{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle San Francisco Crime Classification\n",
    "## Berkeley MIDS W207 Final Project: Sam Goodgame, Sarah Cha, Kalvin Kao, Bryan Moore\n",
    "### Basic Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries:\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import Meta-estimators\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Import Calibration tools\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Set random seed and format print output:\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DDL to construct table for SQL transformations:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE kaggle_sf_crime (\n",
    "dates TIMESTAMP,                                \n",
    "category VARCHAR,\n",
    "descript VARCHAR,\n",
    "dayofweek VARCHAR,\n",
    "pd_district VARCHAR,\n",
    "resolution VARCHAR,\n",
    "addr VARCHAR,\n",
    "X FLOAT,\n",
    "Y FLOAT);\n",
    "```\n",
    "#### Getting training data into a locally hosted PostgreSQL database:\n",
    "```sql\n",
    "\\copy kaggle_sf_crime FROM '/Users/Goodgame/Desktop/MIDS/207/final/sf_crime_train.csv' DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "#### SQL Query used for transformations:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  category,\n",
    "  date_part('hour', dates) AS hour_of_day,\n",
    "  CASE\n",
    "    WHEN dayofweek = 'Monday' then 1\n",
    "    WHEN dayofweek = 'Tuesday' THEN 2\n",
    "    WHEN dayofweek = 'Wednesday' THEN 3\n",
    "    WHEN dayofweek = 'Thursday' THEN 4\n",
    "    WHEN dayofweek = 'Friday' THEN 5\n",
    "    WHEN dayofweek = 'Saturday' THEN 6\n",
    "    WHEN dayofweek = 'Sunday' THEN 7\n",
    "  END AS dayofweek_numeric,\n",
    "  X,\n",
    "  Y,\n",
    "  CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'INGLESIDE' THEN 1\n",
    "    ELSE 0\n",
    "  END AS ingleside_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'NORTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS northern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'CENTRAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS central_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS pd_bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'MISSION' THEN 1\n",
    "    ELSE 0\n",
    "  END AS mission_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'SOUTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS southern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TENDERLOIN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS tenderloin_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'PARK' THEN 1\n",
    "    ELSE 0\n",
    "  END AS park_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'RICHMOND' THEN 1\n",
    "    ELSE 0\n",
    "  END AS richmond_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TARAVAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS taraval_binary\n",
    "FROM kaggle_sf_crime;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into training, development, and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VEHICLE THEFT', 'LIQUOR LAWS', 'LARCENY/THEFT', 'SUSPICIOUS OCC', 'WARRANTS', 'VANDALISM', 'SEX OFFENSES FORCIBLE', 'ARSON', 'GAMBLING', 'TRESPASS', 'PROSTITUTION', 'DRUNKENNESS', 'LOITERING', 'MISSING PERSON', 'BURGLARY', 'SECONDARY CODES', 'FAMILY OFFENSES', 'FRAUD', 'EMBEZZLEMENT', 'EXTORTION', 'KIDNAPPING', 'RECOVERED VEHICLE', 'NON-CRIMINAL', 'RUNAWAY', 'BAD CHECKS', 'WEAPON LAWS', 'ASSAULT', 'SUICIDE', 'DRUG/NARCOTIC', 'STOLEN PROPERTY', 'SEX OFFENSES NON FORCIBLE', 'FORGERY/COUNTERFEITING', 'BRIBERY', 'OTHER OFFENSES', 'ROBBERY', 'DRIVING UNDER THE INFLUENCE', 'DISORDERLY CONDUCT'}\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/train_transformed.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "x_data = df.drop('category', 1)\n",
    "y = df.category.as_matrix()\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "x_complete = x_data.fillna(x_data.mean())\n",
    "X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist:\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "test_data, test_labels = X[800000:], y[800000:]\n",
    "dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "mini_train_data, mini_train_labels = X[:75000], y[:75000]\n",
    "mini_dev_data, mini_dev_labels = X[75000:100000], y[75000:100000]\n",
    "labels_set = set(mini_dev_labels)\n",
    "print(labels_set)\n",
    "print(len(labels_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data, version 2, with weather features to improve performance:\n",
    "\n",
    "We seek to add features to our models that will improve performance with respect to out desired performance metric.  There is evidence that there is a correlation between weather patterns and crime, with some experts even arguing for a causal relationship between weather and crime [1].  More specifically, a 2013 paper published in Science showed that higher temperatures and extreme rainfall led to large increases in conflict.  In the setting of strong evidence that weather influences crime, we see it as a candidate for additional features to improve the performance of our classifiers.  Weather data was gathered from (insert source).  Certain features from this data set were incorporated into the original crime data set in order to add features that were hypothesizzed to improve performance.  These features included (insert what we eventually include)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e9b673f51a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataCSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcsvFields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsvData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train.csv'"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/train_transformed.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "x_data = df.drop('category', 1)\n",
    "y = df.category.as_matrix()\n",
    "\n",
    "########## Adding the date back into the data\n",
    "import csv\n",
    "import time\n",
    "import calendar\n",
    "data_path = \"./data/train.csv\"\n",
    "dataCSV = open(data_path, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allData = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "df2 = pd.DataFrame(allData)\n",
    "df2.columns = csvFields\n",
    "dates = df2['Dates']\n",
    "dates = dates.apply(time.strptime, args=(\"%Y-%m-%d %H:%M:%S\",))\n",
    "dates = dates.apply(calendar.timegm)\n",
    "print(dates.head())\n",
    "#dates = pd.to_datetime(dates)\n",
    "\n",
    "x_data['secondsFromEpoch'] = dates\n",
    "colnames = x_data.columns.tolist()\n",
    "colnames = colnames[-1:] + colnames[:-1]\n",
    "x_data = x_data[colnames]\n",
    "##########\n",
    "\n",
    "########## Adding the weather data into the original crime data\n",
    "weatherData1 = \"./data/1027175.csv\"\n",
    "weatherData2 = \"./data/1027176.csv\"\n",
    "dataCSV = open(weatherData1, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allWeatherData1 = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "dataCSV = open(weatherData2, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allWeatherData2 = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "weatherDF1 = pd.DataFrame(allWeatherData1)\n",
    "weatherDF1.columns = csvFields\n",
    "dates1 = weatherDF1['DATE']\n",
    "\n",
    "weatherDF2 = pd.DataFrame(allWeatherData2)\n",
    "weatherDF2.columns = csvFields\n",
    "dates2 = weatherDF2['DATE']\n",
    "\n",
    "dates1 = dates1.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "dates1 = dates1.apply(calendar.timegm)\n",
    "dates2 = dates2.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "dates2 = dates2.apply(calendar.timegm)\n",
    "weatherDF1['DATE'] = dates1\n",
    "weatherDF2['DATE'] = dates2\n",
    "weatherDF = pd.concat([weatherDF1,weatherDF2[32:]],ignore_index=True)\n",
    "\n",
    "# Starting off with some of the easier features to work with-- more to come here . . . still in beta\n",
    "weatherMetrics = weatherDF[['DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYDewPointTempF', 'HOURLYWindSpeed', 'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY']]\n",
    "weatherMetrics = weatherMetrics.convert_objects(convert_numeric=True)\n",
    "weatherDates = weatherMetrics['DATE']\n",
    "#'DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYDewPointTempF', 'HOURLYWindSpeed',\n",
    "#'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY'\n",
    "timeWindow = 10800 #3 hours\n",
    "hourlyDryBulbTemp = []\n",
    "hourlyRelativeHumidity = []\n",
    "hourlyDewPointTemp = []\n",
    "hourlyWindSpeed = []\n",
    "hourlySeaLevelPressure = []\n",
    "hourlyVisibility = []\n",
    "test = 0\n",
    "for timePoint in dates:#dates is the epoch time from the kaggle data\n",
    "    relevantWeather = weatherMetrics[(weatherDates <= timePoint) & (weatherDates > timePoint - timeWindow)]\n",
    "    hourlyDryBulbTemp.append(relevantWeather['HOURLYDRYBULBTEMPF'].mean())\n",
    "    hourlyRelativeHumidity.append(relevantWeather['HOURLYRelativeHumidity'].mean())\n",
    "    hourlyDewPointTemp.append(relevantWeather['HOURLYDewPointTempF'].mean())\n",
    "    hourlyWindSpeed.append(relevantWeather['HOURLYWindSpeed'].mean())\n",
    "    hourlySeaLevelPressure.append(relevantWeather['HOURLYSeaLevelPressure'].mean())\n",
    "    hourlyVisibility.append(relevantWeather['HOURLYVISIBILITY'].mean())\n",
    "    if test%100000 == 0:\n",
    "        print(relevantWeather)\n",
    "    test += 1\n",
    "\n",
    "hourlyDryBulbTemp = pd.Series.from_array(np.array(hourlyDryBulbTemp))\n",
    "hourlyRelativeHumidity = pd.Series.from_array(np.array(hourlyRelativeHumidity))\n",
    "hourlyDewPointTemp = pd.Series.from_array(np.array(hourlyDewPointTemp))\n",
    "hourlyWindSpeed = pd.Series.from_array(np.array(hourlyWindSpeed))\n",
    "hourlySeaLevelPressure = pd.Series.from_array(np.array(hourlySeaLevelPressure))\n",
    "hourlyVisibility = pd.Series.from_array(np.array(hourlyVisibility))\n",
    "\n",
    "x_data['HOURLYDRYBULBTEMPF'] = hourlyDryBulbTemp\n",
    "x_data['HOURLYRelativeHumidity'] = hourlyRelativeHumidity\n",
    "x_data['HOURLYDewPointTempF'] = hourlyDewPointTemp\n",
    "x_data['HOURLYWindSpeed'] = hourlyWindSpeed\n",
    "x_data['HOURLYSeaLevelPressure'] = hourlySeaLevelPressure\n",
    "x_data['HOURLYVISIBILITY'] = hourlyVisibility\n",
    "\n",
    "#x_data.to_csv(path_or_buf=\"C:/MIDS/W207 final project/x_data.csv\")\n",
    "##########\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "x_complete = x_data.fillna(x_data.mean())\n",
    "X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist:\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "#X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "#test_data, test_labels = X[800000:], y[800000:]\n",
    "#dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "#train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "#mini_train_data, mini_train_labels = X[:75000], y[:75000]\n",
    "#mini_dev_data, mini_dev_labels = X[75000:100000], y[75000:100000]\n",
    "\n",
    "#print(train_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting to meet Kaggle submission standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Kaggle submission format requires listing the ID of each example.\n",
    "# This is to remember the order of the IDs after shuffling\n",
    "allIDs = np.array(list(df.axes[0]))\n",
    "allIDs = allIDs[shuffle]\n",
    "\n",
    "testIDs = allIDs[800000:]\n",
    "devIDs = allIDs[700000:800000]\n",
    "trainIDs = allIDs[:700000]\n",
    "\n",
    "# Extract the column names for the required submission format\n",
    "sampleSubmission_path = \"./data/sampleSubmission.csv\"\n",
    "sampleDF = pd.read_csv(sampleSubmission_path)\n",
    "allColumns = list(sampleDF.columns)\n",
    "featureColumns = allColumns[1:]\n",
    "\n",
    "# Extracting the test data for a baseline submission\n",
    "real_test_path = \"./data/test_transformed.csv\"\n",
    "testDF = pd.read_csv(real_test_path, header=0)\n",
    "real_test_data = testDF\n",
    "\n",
    "test_complete = real_test_data.fillna(real_test_data.mean())\n",
    "Test_raw = test_complete.as_matrix()\n",
    "\n",
    "TestData = MinMaxScaler().fit_transform(Test_raw)\n",
    "\n",
    "# Here we remember the ID of each test data point, in case we ever decide to shuffle the test data for some reason\n",
    "testIDs = list(testDF.axes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate baseline prediction probabilities from MNB classifier and store in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a baseline MNB classifier and make it return prediction probabilities for the actual test data\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    #print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "    return mnb.predict_proba(real_test_data)\n",
    "MNB()\n",
    "\n",
    "baselinePredictionProbabilities = MNB()\n",
    "\n",
    "# Place the resulting prediction probabilities in a .csv file in the required format\n",
    "# First, turn the prediction probabilties into a data frame\n",
    "resultDF = pd.DataFrame(baselinePredictionProbabilities,columns=featureColumns)\n",
    "# Add the IDs as a final column\n",
    "resultDF.loc[:,'Id'] = pd.Series(testIDs,index=resultDF.index)\n",
    "# Make the 'Id' column the first column\n",
    "colnames = resultDF.columns.tolist()\n",
    "colnames = colnames[-1:] + colnames[:-1]\n",
    "resultDF = resultDF[colnames]\n",
    "# Output to a .csv file\n",
    "resultDF.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: the code above will shuffle data differently every time it's run, so model accuracies will vary accordingly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.391e-01   6.667e-01   6.117e-02   9.047e-04   1.000e+00   0.000e+00\n",
      "    0.000e+00   0.000e+00   1.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "    0.000e+00   0.000e+00   0.000e+00]]\n",
      "['WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "## Data sub-setting quality check-point\n",
    "print(train_data[:1])\n",
    "print(train_labels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB accuracy on dev data: 0.22314\n"
     ]
    }
   ],
   "source": [
    "# Modeling quality check-point with MNB--fast model\n",
    "\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "    \n",
    "MNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Performance Criteria\n",
    "\n",
    "As determined by the Kaggle submission guidelines, the performance criteria metric for the San Francisco Crime Classification competition is Multi-class Logarithmic Loss (also known as cross-entropy).  There are various other performance metrics that are appropriate for different domains: accuracy, F-score, Lift, ROC Area, average precision, precision/recall break-even point, and squared error.\n",
    "\n",
    "(Describe each performance metric and a domain in which it is preferred. Give Pros/Cons if able)\n",
    "\n",
    "- Multi-class Log Loss:\n",
    "\n",
    "- Accuracy:\n",
    "\n",
    "- F-score:\n",
    "\n",
    "- Lift:\n",
    "\n",
    "- ROC Area:\n",
    "\n",
    "- Average precision\n",
    "\n",
    "- Precision/Recall break-even point:\n",
    "\n",
    "- Squared-error:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prototyping\n",
    "We will start our classifier and feature engineering process by looking at the performance of various classifiers with default parameter settings in predicting labels on the mini_dev_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes in labels is different from that in y_pred. Classes found in labels: ['ARSON' 'ASSAULT' 'BAD CHECKS' 'BRIBERY' 'BURGLARY' 'DISORDERLY CONDUCT'\n 'DRIVING UNDER THE INFLUENCE' 'DRUG/NARCOTIC' 'DRUNKENNESS' 'EMBEZZLEMENT'\n 'EXTORTION' 'FAMILY OFFENSES' 'FORGERY/COUNTERFEITING' 'FRAUD' 'GAMBLING'\n 'KIDNAPPING' 'LARCENY/THEFT' 'LIQUOR LAWS' 'LOITERING' 'MISSING PERSON'\n 'NON-CRIMINAL' 'OTHER OFFENSES' 'PROSTITUTION' 'ROBBERY' 'RUNAWAY'\n 'SECONDARY CODES' 'SEX OFFENSES FORCIBLE' 'STOLEN PROPERTY'\n 'SUSPICIOUS OCC' 'TRESPASS' 'VANDALISM' 'VEHICLE THEFT' 'WARRANTS'\n 'WEAPON LAWS']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-af22398c4cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Multi-class Log Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_prediction_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrime_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_dev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_dev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-af22398c4cea>\u001b[0m in \u001b[0;36mmodel_prototype\u001b[0;34m(train_data, train_labels, eval_data, eval_labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mset_eval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcrime_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_eval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Multi-class Log Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_prediction_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrime_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_dev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_dev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             raise ValueError('The number of classes in labels is different '\n\u001b[1;32m   1657\u001b[0m                              \u001b[0;34m'from that in y_pred. Classes found in '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m                              'labels: {0}'.format(lb.classes_))\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;31m# Renormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes in labels is different from that in y_pred. Classes found in labels: ['ARSON' 'ASSAULT' 'BAD CHECKS' 'BRIBERY' 'BURGLARY' 'DISORDERLY CONDUCT'\n 'DRIVING UNDER THE INFLUENCE' 'DRUG/NARCOTIC' 'DRUNKENNESS' 'EMBEZZLEMENT'\n 'EXTORTION' 'FAMILY OFFENSES' 'FORGERY/COUNTERFEITING' 'FRAUD' 'GAMBLING'\n 'KIDNAPPING' 'LARCENY/THEFT' 'LIQUOR LAWS' 'LOITERING' 'MISSING PERSON'\n 'NON-CRIMINAL' 'OTHER OFFENSES' 'PROSTITUTION' 'ROBBERY' 'RUNAWAY'\n 'SECONDARY CODES' 'SEX OFFENSES FORCIBLE' 'STOLEN PROPERTY'\n 'SUSPICIOUS OCC' 'TRESPASS' 'VANDALISM' 'VEHICLE THEFT' 'WARRANTS'\n 'WEAPON LAWS']"
     ]
    }
   ],
   "source": [
    "def model_prototype(train_data, train_labels, eval_data, eval_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(train_data, train_labels)\n",
    "    bnb = BernoulliNB(alpha=1, binarize = 0.5).fit(train_data, train_labels)\n",
    "    mnb = MultinomialNB().fit(train_data, train_labels)\n",
    "    log_reg = LogisticRegression().fit(train_data, train_labels)\n",
    "    support_vm = svm.SVC().fit(train_data, train_labels)\n",
    "    neural_net = MLPClassifier().fit(train_data, train_labels)\n",
    "    random_forest = RandomForestClassifier().fit(train_data, train_labels)\n",
    "    decision_tree = DecisionTreeClassifier().fit(train_data, train_labels)\n",
    "    \n",
    "    models = [knn, bnb, mnb, log_reg, support_vm, neural_net, random_forest, decision_tree]\n",
    "    for model in models:\n",
    "        eval_prediction_probabilities = model.predict_proba(eval_data)\n",
    "        eval_predictions = model.predict(eval_data)\n",
    "        set_eval_predictions = set(eval_predictions)\n",
    "        crime_labels = list(set_eval_predictions)\n",
    "        print(model, \"Multi-class Log Loss:\", log_loss(y_true = eval_labels, y_pred = eval_prediction_probabilities, labels = crime_labels), \"\\n\\n\")\n",
    "\n",
    "model_prototype(mini_train_data, mini_train_labels, mini_dev_data, mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Features, Hyperparameter Tuning, and Model Calibration To Improve Prediction For Each Classifier\n",
    "\n",
    "Here we seek to optimize the performance of our classifiers in a three-step, dynamnic engineering process. \n",
    "\n",
    "##### 1) Feature addition\n",
    "\n",
    "We previously added components from the weather data into the original SF crime data as new features.  Here, we will incorporate those features into our classifiers to determine whether or not they improve performance as hypothesized.\n",
    "\n",
    "##### 2) Hyperparameter tuning\n",
    "\n",
    "Each classifier has parameters that we can engineer to further optimize performance, as opposed to using the default parameter values as we did above in the model prototyping cell. (Will likely use pipeline here in future)\n",
    "\n",
    "##### 3) Model calibration\n",
    "\n",
    "We can calibrate the models via Platt Scaling or Isotonic Regression to attempt to improve their performance.\n",
    "\n",
    "- Platt Scaling: (brief explanation of how it works)\n",
    "\n",
    "- Isotonic Regression: ((brief explanation of how it works))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Addition\n",
    "\n",
    "(Decide whether to do this as one big step, or to engineer the addition of individual features for individual classifiers.  Can likely do all feature addition here, continuing on the work done with the weather data import completed in earlier cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Feature addition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def k_neighbors_tuned():\n",
    "    \n",
    "    k_value_tuning = [i for i in range(1,100,2)]\n",
    "    weight_tuning = ['uniform', 'distance']\n",
    "    power_parameter_tuning = [1,2]\n",
    "    for k in k_value_tuning:\n",
    "        for w in weight_tuning:\n",
    "            for p in power_parameter_tuning:\n",
    "                tuned_KNN = KNeighborsClassifier(n_neighbors=k, weights=w, p=p).fit(train_data, train_labels)\n",
    "                dev_preds = tuned_KNN.predict(dev_data)\n",
    "                set_dev_preds = set(dev_preds)\n",
    "                crime_labels_tuned = list(set_dev_preds)\n",
    "                dev_prediction_probabilities = tuned_KNN.predict_proba(dev_data)\n",
    "                print(tuned_KNN, \"Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_tuned), \"\\n\\n\")\n",
    "\n",
    "# k_neighbors_tuned()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def k_calibrated():\n",
    "\n",
    "# Here we will calibrate the KNN classifier with both Platt Scaling and with Isotonic Regression using CalibratedClassifierCV\n",
    "# with various parameter settings.  The \"method\" parameter can be set to \"sigmoid\" or to \"isotonic\", \n",
    "# corresponding to Platt Scaling and to Isotonic Regression respectively.\n",
    "\n",
    "    methods = ['signoid', 'isotonic']\n",
    "    for m in methods:\n",
    "        CCV_for_KNN = CalibratedClassifierCV()\n",
    "        \n",
    "        # Will likely embed this step within the for loop for the hyperparameter tuning as that makes more sense. #\n",
    "        # Or will pipeline it along with the hyperparameter tuning steps #\n",
    "\n",
    "# k_calibrated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial, Bernoulli, and Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB accuracy on dev data: 0.22314\n",
      "GaussianNB accuracy on dev data: 0.0062\n",
      "GaussianNB accuracy with added noise: 0.06857\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes accuracy when alpha = 1 (the default value): 0.22189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB accuracy when alpha = 0: 0.00155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for BNB on the dev data: {'alpha': 1e-23}\n",
      "Accuracy using the tuned Laplace smoothing parameter: 0.22189 \n",
      "\n",
      "\n",
      "p(pred) <= 0.5000000000000    total = 100000    accuracy = 0.222\n",
      "p(pred) <= 0.9000000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9900000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9990000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999900000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 1.0000000000000    total =   0    accuracy = 0.000\n"
     ]
    }
   ],
   "source": [
    "def GNB():\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, train_labels)\n",
    "    print(\"GaussianNB accuracy on dev data:\", \n",
    "          gnb.score(dev_data, dev_labels))\n",
    "    \n",
    "    # Gaussian Naive Bayes requires the data to have a relative normal distribution. Sometimes\n",
    "    # adding noise can improve performance by making the data more normal:\n",
    "    train_data_noise = np.random.rand(train_data.shape[0],train_data.shape[1])\n",
    "    modified_train_data = np.multiply(train_data,train_data_noise)    \n",
    "    gnb_noise = GaussianNB()\n",
    "    gnb.fit(modified_train_data, train_labels)\n",
    "    print(\"GaussianNB accuracy with added noise:\", \n",
    "          gnb.score(dev_data, dev_labels))    \n",
    "    \n",
    "# Going slightly deeper with hyperparameter tuning and model calibration:\n",
    "def BNB(alphas):\n",
    "    \n",
    "    bnb_one = BernoulliNB(binarize = 0.5)\n",
    "    bnb_one.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nBernoulli Naive Bayes accuracy when alpha = 1 (the default value):\",\n",
    "          bnb_one.score(dev_data, dev_labels))\n",
    "    \n",
    "    bnb_zero = BernoulliNB(binarize = 0.5, alpha=0)\n",
    "    bnb_zero.fit(train_data, train_labels)\n",
    "    print(\"BNB accuracy when alpha = 0:\", bnb_zero.score(dev_data, dev_labels))\n",
    "    \n",
    "    bnb = BernoulliNB(binarize=0.5)\n",
    "    clf = GridSearchCV(bnb, param_grid = alphas)\n",
    "    clf.fit(train_data, train_labels)\n",
    "    print(\"Best parameter for BNB on the dev data:\", clf.best_params_)\n",
    "    \n",
    "    clf_tuned = BernoulliNB(binarize = 0.5, alpha=0.00000000000000000000001)\n",
    "    clf_tuned.fit(train_data, train_labels)\n",
    "    print(\"Accuracy using the tuned Laplace smoothing parameter:\", \n",
    "          clf_tuned.score(dev_data, dev_labels), \"\\n\\n\")\n",
    "    \n",
    "\n",
    "def investigate_model_calibration(buckets, correct, total):\n",
    "    clf_tuned = BernoulliNB(binarize = 0.5, alpha=0.00000000000000000000001)\n",
    "    clf_tuned.fit(train_data, train_labels)\n",
    "    \n",
    "    # Establish data sets\n",
    "    pred_probs = clf_tuned.predict_proba(dev_data)\n",
    "    max_pred_probs = np.array(pred_probs.max(axis=1))\n",
    "    preds = clf_tuned.predict(dev_data)\n",
    "        \n",
    "    # For each bucket, look at the predictions that the model yields. \n",
    "    # Keep track of total & correct predictions within each bucket.\n",
    "    bucket_bottom = 0\n",
    "    bucket_top = 0\n",
    "    for bucket_index, bucket in enumerate(buckets):\n",
    "        bucket_top = bucket\n",
    "        for pred_index, pred in enumerate(preds):\n",
    "            if (max_pred_probs[pred_index] <= bucket_top) and (max_pred_probs[pred_index] > bucket_bottom):\n",
    "                total[bucket_index] += 1\n",
    "                if preds[pred_index] == dev_labels[pred_index]:\n",
    "                    correct[bucket_index] += 1\n",
    "        bucket_bottom = bucket_top\n",
    "\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "\n",
    "alphas = {'alpha': [0.00000000000000000000001, 0.0000001, 0.0001, 0.001, \n",
    "                    0.01, 0.1, 0.0, 0.5, 1.0, 2.0, 10.0]}\n",
    "buckets = [0.5, 0.9, 0.99, 0.999, .9999, 0.99999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "MNB()\n",
    "GNB()\n",
    "BNB(alphas)\n",
    "investigate_model_calibration(buckets, correct, total)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "   accuracy = 0.0\n",
    "   if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "   print('p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Naive Bayes and Multinomial Naive Bayes models can predict whether a loan will be good or bad with XXX% accuracy.\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "The optimal Laplace smoothing parameter $\\alpha$ for the Bernoulli NB model:\n",
    "\n",
    "###### Model calibration:\n",
    "Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "###### Model calibration:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "###### Model calibration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "###### Model calibration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Nets\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "###### Model calibration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "\n",
    "###### Hyperparameter tuning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier\n",
    "\n",
    "###### Hyperparameter tuning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "\n",
    "###### Hyperparameter tuning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform') Accuracy: 0.9453125 \n",
      "\n",
      "\n",
      "BernoulliNB(alpha=1e-22, binarize=0.5, class_prior=None, fit_prior=True) Accuracy: 0.947265625 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def model_test(train_data, train_labels, eval_data, eval_labels):\n",
    "#     '''Similar to the initial model prototyping, but using the \n",
    "#     tuned parameters on data that none of the models have yet\n",
    "#     encountered.'''\n",
    "#     knn = KNeighborsClassifier(n_neighbors=7).fit(train_data, train_labels)\n",
    "#     bnb = BernoulliNB(alpha=0.0000000000000000000001, binarize = 0.5).fit(train_data, train_labels)\n",
    "    \n",
    "#     models = [knn, bnb]\n",
    "#     for model in models:\n",
    "#         eval_preds = model.predict(eval_data)\n",
    "#         print(model, \"Accuracy:\", np.mean(eval_preds==eval_labels), \"\\n\\n\")\n",
    "\n",
    "# model_test(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1) Hsiang, Solomon M. and Burke, Marshall and Miguel, Edward. \"Quantifying the Influence of Climate on Human Conflict\". Science, Vol 341, Issue 6151, 2013   \n",
    "\n",
    "2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
