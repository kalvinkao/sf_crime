{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle San Francisco Crime Classification: Supporting Notebook\n",
    "## UCB MIDS W207 Final Project: Sam Goodgame, Sarah Cha, Kalvin Kao, Bryan Moore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook will supoort the final, refined notebook submitted for the Berkeley MIDS W207 Final Project.  This notebook contains code and markdown that contirbuted to our final notebook, graphs, and formal presentation.  It serves as a reference for the final notebook.\n",
    "\n",
    "Throughout this notebook, there are local dependencies that will require data pathways to local files.  These will be supressed for viewing comfort, as to not overwhelm the notebook with errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries:\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Import Meta-estimators\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Import Calibration tools\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Set random seed and format print output:\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we include the data definition language that we wrote to bring our csv data into formatted tables:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE kaggle_sf_crime (\n",
    "dates TIMESTAMP,                                \n",
    "category VARCHAR,\n",
    "descript VARCHAR,\n",
    "dayofweek VARCHAR,\n",
    "pd_district VARCHAR,\n",
    "resolution VARCHAR,\n",
    "addr VARCHAR,\n",
    "X FLOAT,\n",
    "Y FLOAT);\n",
    "```\n",
    "\n",
    "#### Getting training data into a locally hosted PostgreSQL database:\n",
    "```sql\n",
    "\\copy kaggle_sf_crime FROM '/Users/Goodgame/Desktop/MIDS/207/final/sf_crime_train.csv' DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "#### SQL Query used to perform out transformations:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  category,\n",
    "  date_part('hour', dates) AS hour_of_day,\n",
    "  CASE\n",
    "    WHEN dayofweek = 'Monday' then 1\n",
    "    WHEN dayofweek = 'Tuesday' THEN 2\n",
    "    WHEN dayofweek = 'Wednesday' THEN 3\n",
    "    WHEN dayofweek = 'Thursday' THEN 4\n",
    "    WHEN dayofweek = 'Friday' THEN 5\n",
    "    WHEN dayofweek = 'Saturday' THEN 6\n",
    "    WHEN dayofweek = 'Sunday' THEN 7\n",
    "  END AS dayofweek_numeric,\n",
    "  X,\n",
    "  Y,\n",
    "  CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'INGLESIDE' THEN 1\n",
    "    ELSE 0\n",
    "  END AS ingleside_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'NORTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS northern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'CENTRAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS central_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS pd_bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'MISSION' THEN 1\n",
    "    ELSE 0\n",
    "  END AS mission_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'SOUTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS southern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TENDERLOIN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS tenderloin_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'PARK' THEN 1\n",
    "    ELSE 0\n",
    "  END AS park_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'RICHMOND' THEN 1\n",
    "    ELSE 0\n",
    "  END AS richmond_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TARAVAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS taraval_binary\n",
    "FROM kaggle_sf_crime;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial source of our data was at https://www.kaggle.com/c/sf-crime.  We loaded the original training data, train.csv, then extracted the dates column and added it to the transformed data.  Dates were converted to number of seconds from the Unix epoch\n",
    "(defined as the number of seconds that have elapsed since 00:00:00 Coordinated Universal Time (UTC), Thursday, 1 January 1970, minus the number of leap seconds that have taken place since then).  We then moved the dates to the first column.\n",
    "\n",
    "Next, we one-hot encoded the location data.  Location information tends to be extremely high-dimensional, which presents difficulties for modeling. The original dataset's location information came in three major formats: \n",
    "\n",
    "1. X and Y coordinates\n",
    "2. Street address information\n",
    "3. Police department districts\n",
    "\n",
    "After visualizing the data and conducting basic exploratory data analysis, we decided to use one-hot encoding to transform the police department location information into features. In other words, each police department becomes a feature, and a given observation receives a value of '1' if it occurred in the police department jurisdiction described by the feature. Otherwise, it received a value of '0'.  Approaching location in this way allowed us to preserve the parsimony of our model; it retains the majority of the important variance in the data without overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Weather Data, School Data, and Zipcode Data\n",
    "\n",
    "We sought to add features to our models that would improve performance with respect to our desired performance metric of Multi-class Log Loss.  There is evidence that there is a correlation between weather patterns and crime, with some experts even arguing for a causal relationship between weather and crime [1].  More specifically, a 2013 paper published in Science showed that higher temperatures and extreme rainfall led to large increases in conflict.  In the setting of strong evidence that weather influences crime, we saw it as a candidate for additional features to improve the performance of our classifiers.  Weather data was gathered from the National Centers for Environmental Information (specifically, the National Oceanic and Atmospheric Administration).  Certain features from this data set were incorporated into the original crime data set in order to add features that were hypothesizzed to improve performance.  These features included:\n",
    "\n",
    "- Hourly Dry Bulb Temperature\n",
    "- Hourly Relative Humidity\n",
    "- Hourly Wind Speed\n",
    "- Hourly Seal Level Pressure\n",
    "- Hourly Visibility\n",
    "- Daylight: a daylight indicator (1 if time of sunrise < timestamp < time of sunset, and 0 otherwise)\n",
    "\n",
    "Details on School data and Zipcode data are below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data With Additional Features\n",
    "\n",
    "### There are local file dependencies here.  For viewing comfort, we will suppress the code in order to not generate error messages.  The code that follows was written by us to incorporate the weather data features into the original data from Kaggle, and to load and then subset the data into train, development, calibrate, and test subsets.\n",
    "\n",
    "### A separate portion of code follows that was used to load the data from the CSV file that is generated from the code here.  Further details on data cleaning will be provided there.\n",
    "\n",
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_path = \"./data/train_transformed.csv\"\n",
    "\n",
    "#df = pd.read_csv(data_path, header=0)\n",
    "#x_data = df.drop('category', 1)\n",
    "#y = df.category.as_matrix()\n",
    "\n",
    "########## Adding the date back into the data\n",
    "#import csv\n",
    "#import time\n",
    "#import calendar\n",
    "#data_path = \"./data/train.csv\"\n",
    "#dataCSV = open(data_path, 'rt')\n",
    "#csvData = list(csv.reader(dataCSV))\n",
    "#csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#allData = csvData[1:]\n",
    "#dataCSV.close()\n",
    "\n",
    "#df2 = pd.DataFrame(allData)\n",
    "#df2.columns = csvFields\n",
    "#dates = df2['Dates']\n",
    "#dates = dates.apply(time.strptime, args=(\"%Y-%m-%d %H:%M:%S\",))\n",
    "#dates = dates.apply(calendar.timegm)\n",
    "#print(dates.head())\n",
    "\n",
    "#x_data['secondsFromEpoch'] = dates\n",
    "#colnames = x_data.columns.tolist()\n",
    "#colnames = colnames[-1:] + colnames[:-1]\n",
    "#x_data = x_data[colnames]\n",
    "##########\n",
    "\n",
    "########## Adding the weather data into the original crime data\n",
    "#weatherData1 = \"./data/1027175.csv\"\n",
    "#weatherData2 = \"./data/1027176.csv\"\n",
    "#dataCSV = open(weatherData1, 'rt')\n",
    "#csvData = list(csv.reader(dataCSV))\n",
    "#csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#allWeatherData1 = csvData[1:]\n",
    "#dataCSV.close()\n",
    "\n",
    "#dataCSV = open(weatherData2, 'rt')\n",
    "#csvData = list(csv.reader(dataCSV))\n",
    "#csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#allWeatherData2 = csvData[1:]\n",
    "#dataCSV.close()\n",
    "\n",
    "#weatherDF1 = pd.DataFrame(allWeatherData1)\n",
    "#weatherDF1.columns = csvFields\n",
    "#dates1 = weatherDF1['DATE']\n",
    "#sunrise1 = weatherDF1['DAILYSunrise']\n",
    "#sunset1 = weatherDF1['DAILYSunset']\n",
    "\n",
    "#weatherDF2 = pd.DataFrame(allWeatherData2)\n",
    "#weatherDF2.columns = csvFields\n",
    "#dates2 = weatherDF2['DATE']\n",
    "#sunrise2 = weatherDF2['DAILYSunrise']\n",
    "#sunset2 = weatherDF2['DAILYSunset']\n",
    "\n",
    "#functions for processing the sunrise and sunset times of each day\n",
    "#def get_hour_and_minute(milTime):\n",
    " #   hour = int(milTime[:-2])\n",
    " #   minute = int(milTime[-2:])\n",
    " #   return [hour, minute]\n",
    "\n",
    "#def get_date_only(date):\n",
    "#    return time.struct_time(tuple([date[0], date[1], date[2], 0, 0, 0, date[6], date[7], date[8]]))\n",
    "\n",
    "#def structure_sun_time(timeSeries, dateSeries):\n",
    "#    sunTimes = timeSeries.copy()\n",
    "#    for index in range(len(dateSeries)):\n",
    "#        sunTimes[index] = time.struct_time(tuple([dateSeries[index][0], dateSeries[index][1], dateSeries[index][2], timeSeries[index][0], timeSeries[index][1], dateSeries[index][5], dateSeries[index][6], dateSeries[index][7], dateSeries[index][8]]))\n",
    "#    return sunTimes\n",
    "\n",
    "#dates1 = dates1.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "#sunrise1 = sunrise1.apply(get_hour_and_minute)\n",
    "#sunrise1 = structure_sun_time(sunrise1, dates1)\n",
    "#sunrise1 = sunrise1.apply(calendar.timegm)\n",
    "#sunset1 = sunset1.apply(get_hour_and_minute)\n",
    "#sunset1 = structure_sun_time(sunset1, dates1)\n",
    "#sunset1 = sunset1.apply(calendar.timegm)\n",
    "#dates1 = dates1.apply(calendar.timegm)\n",
    "\n",
    "#dates2 = dates2.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "#sunrise2 = sunrise2.apply(get_hour_and_minute)\n",
    "#sunrise2 = structure_sun_time(sunrise2, dates2)\n",
    "#sunrise2 = sunrise2.apply(calendar.timegm)\n",
    "#sunset2 = sunset2.apply(get_hour_and_minute)\n",
    "#sunset2 = structure_sun_time(sunset2, dates2)\n",
    "#sunset2 = sunset2.apply(calendar.timegm)\n",
    "#dates2 = dates2.apply(calendar.timegm)\n",
    "\n",
    "#weatherDF1['DATE'] = dates1\n",
    "#weatherDF1['DAILYSunrise'] = sunrise1\n",
    "#weatherDF1['DAILYSunset'] = sunset1\n",
    "#weatherDF2['DATE'] = dates2\n",
    "#weatherDF2['DAILYSunrise'] = sunrise2\n",
    "#weatherDF2['DAILYSunset'] = sunset2\n",
    "\n",
    "#weatherDF = pd.concat([weatherDF1,weatherDF2[32:]],ignore_index=True)\n",
    "\n",
    "# Starting off with some of the easier features to work with-- more to come here . . . still in beta\n",
    "#weatherMetrics = weatherDF[['DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYWindSpeed', \\\n",
    "#                            'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY', 'DAILYSunrise', 'DAILYSunset']]\n",
    "#weatherMetrics = weatherMetrics.convert_objects(convert_numeric=True)\n",
    "#weatherDates = weatherMetrics['DATE']\n",
    "#'DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYWindSpeed',\n",
    "#'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY'\n",
    "#timeWindow = 10800 #3 hours\n",
    "#hourlyDryBulbTemp = []\n",
    "#hourlyRelativeHumidity = []\n",
    "#hourlyWindSpeed = []\n",
    "#hourlySeaLevelPressure = []\n",
    "#hourlyVisibility = []\n",
    "#dailySunrise = []\n",
    "#dailySunset = []\n",
    "#daylight = []\n",
    "#test = 0\n",
    "#for timePoint in dates:#dates is the epoch time from the kaggle data\n",
    "#    relevantWeather = weatherMetrics[(weatherDates <= timePoint) & (weatherDates > timePoint - timeWindow)]\n",
    "#    hourlyDryBulbTemp.append(relevantWeather['HOURLYDRYBULBTEMPF'].mean())\n",
    "#    hourlyRelativeHumidity.append(relevantWeather['HOURLYRelativeHumidity'].mean())\n",
    "#    hourlyWindSpeed.append(relevantWeather['HOURLYWindSpeed'].mean())\n",
    "#    hourlySeaLevelPressure.append(relevantWeather['HOURLYSeaLevelPressure'].mean())\n",
    "#    hourlyVisibility.append(relevantWeather['HOURLYVISIBILITY'].mean())\n",
    "#    dailySunrise.append(relevantWeather['DAILYSunrise'].iloc[-1])\n",
    "#    dailySunset.append(relevantWeather['DAILYSunset'].iloc[-1])\n",
    "#    daylight.append(1.0*((timePoint >= relevantWeather['DAILYSunrise'].iloc[-1]) and (timePoint < relevantWeather['DAILYSunset'].iloc[-1])))\n",
    "    #if timePoint < relevantWeather['DAILYSunset'][-1]:\n",
    "        #daylight.append(1)\n",
    "    #else:\n",
    "        #daylight.append(0)\n",
    "    \n",
    "#    if test%100000 == 0:\n",
    "#        print(relevantWeather)\n",
    "#    test += 1\n",
    "\n",
    "#hourlyDryBulbTemp = pd.Series.from_array(np.array(hourlyDryBulbTemp))\n",
    "#hourlyRelativeHumidity = pd.Series.from_array(np.array(hourlyRelativeHumidity))\n",
    "#hourlyWindSpeed = pd.Series.from_array(np.array(hourlyWindSpeed))\n",
    "#hourlySeaLevelPressure = pd.Series.from_array(np.array(hourlySeaLevelPressure))\n",
    "#hourlyVisibility = pd.Series.from_array(np.array(hourlyVisibility))\n",
    "#dailySunrise = pd.Series.from_array(np.array(dailySunrise))\n",
    "#dailySunset = pd.Series.from_array(np.array(dailySunset))\n",
    "#daylight = pd.Series.from_array(np.array(daylight))\n",
    "\n",
    "#x_data['HOURLYDRYBULBTEMPF'] = hourlyDryBulbTemp\n",
    "#x_data['HOURLYRelativeHumidity'] = hourlyRelativeHumidity\n",
    "#x_data['HOURLYWindSpeed'] = hourlyWindSpeed\n",
    "#x_data['HOURLYSeaLevelPressure'] = hourlySeaLevelPressure\n",
    "#x_data['HOURLYVISIBILITY'] = hourlyVisibility\n",
    "#x_data['DAILYSunrise'] = dailySunrise\n",
    "#x_data['DAILYSunset'] = dailySunset\n",
    "#x_data['Daylight'] = daylight\n",
    "\n",
    "#x_data.to_csv(path_or_buf=\"C:/MIDS/W207 final project/x_data.csv\")\n",
    "##########\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "#x_complete = x_data.fillna(x_data.mean())\n",
    "#X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "#X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist:\n",
    "#shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "#X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "#test_data, test_labels = X[800000:], y[800000:]\n",
    "#dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "#train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "#mini_train_data, mini_train_labels = X[:75000], y[:75000]\n",
    "#mini_dev_data, mini_dev_labels = X[75000:100000], y[75000:100000]\n",
    "#labels_set = set(mini_dev_labels)\n",
    "#print(labels_set)\n",
    "#print(len(labels_set))\n",
    "#print(train_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### School Data\n",
    "\n",
    "We hypothesized that incorporating data on school location as well as other details on schools as features would increase the performance of our classifiers.  We found a data set offered by California Department of Education (cde.ca.gov) with a list of all schools (K-12) in California and accompanying characteristics of those schools including activity status, grades taught (elementary vs middle vs high school), and address, including location coordinates. We created a distance function to match the longitude, latitude coordinates of each of the crimes to the closest school and pulled other potentially interesting features including: \n",
    "\n",
    "1. ‘Closest_school’ - Name of closest school\n",
    "2. ‘School_distance’ - Euclidean distance between latitude/longitude coordinates of crime and latitude/longitude coordinates of school\n",
    "3. ‘School_type’ - Elementary school vs Middle school vs High school\n",
    "\n",
    "Ultimately, we were not able to get these features incorporated into our data, although the attempt was educational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Read in school data\n",
    "#data_path_schools = \"./data/pubschls.csv\"\n",
    "#schools = pd.read_csv(data_path_schools,header=0, sep ='\\t', usecols = [\"CDSCode\",\"StatusType\", \"School\", \"EILCode\", \"EILName\", \"Zip\", \"Latitude\", \"Longitude\"], dtype ={'CDSCode': str, 'StatusType': str, 'School': str, 'EILCode': str,'EILName': str,'Zip': str, 'Latitude': float, 'Longitude': float})\n",
    "#schools = schools[(schools[\"StatusType\"] == 'Active')]\n",
    "\n",
    "### Find the closest school\n",
    "#def dist(lat1, long1, lat2, long2):\n",
    "#    return np.sqrt((lat1-lat2)**2+(long1-long2)**2)\n",
    "\n",
    "#def find_closest_school(lat, long):    \n",
    "#    distances = schools.apply(lambda row: dist(lat, long, row[\"Latitude\"], row[\"Longitude\"]), axis=1)\n",
    "#    return min(distances)\n",
    "#x_data['closest_school'] = x_data_sub.apply(lambda row: find_closest_school(row['y'], row['x']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipcode Data\n",
    "\n",
    "We found government data from data.gov that links each zip code in the country to longitude and latitude coordinates in an effort to reduce location dimensions from 2 to 1. We used a custom distance function to map each set of longitude, latitude coordinates associated with each crime incident to find the closest 5-digit zip code using the data.gov file. Unfortunately even after we narrowed the data California zip codes (> 94000 and < 95000) we were unable to run the data in time to add the feature to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Read in zip code data\n",
    "#data_path_zip = \"./data/2016_zips.csv\"\n",
    "#zips = pd.read_csv(data_path_zip, header=0, sep ='\\t', usecols = [0,5,6], names = [\"GEOID\", \"INTPTLAT\", \"INTPTLONG\"], dtype ={'GEOID': int, 'INTPTLAT': float, 'INTPTLONG': float})\n",
    "#sf_zips = zips[(zips['GEOID'] > 94000) & (zips['GEOID'] < 94189)]\n",
    "\n",
    "### Mapping longitude/latitude to zipcodes\n",
    "#def dist(lat1, long1, lat2, long2):\n",
    "#    return np.sqrt((lat1-lat2)**2+(long1-long2)**2)\n",
    "#    return abs(lat1-lat2)+abs(long1-long2)\n",
    "#def find_zipcode(lat, long):    \n",
    "#    distances = sf_zips.apply(lambda row: dist(lat, long, row[\"INTPTLAT\"], row[\"INTPTLONG\"]), axis=1)\n",
    "#    return sf_zips.loc[distances.idxmin(), \"GEOID\"]\n",
    "#x_data['zipcode'] = 0\n",
    "#for i in range(0, 1):\n",
    "#    x_data['zipcode'][i] = x_data.apply(lambda row: find_zipcode(row['x'], row['y']), axis=1)\n",
    "#x_data['zipcode']= x_data.apply(lambda row: find_zipcode(row['x'], row['y']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local, individual clean and load of the updated data set (with weather data integrated) generated by the previous cells.\n",
    "\n",
    "Our final set of features was:\n",
    "\n",
    "1. hour_of_day\n",
    "2. dayofweek_numeric\n",
    "3. x: is this the longitude of the crime?\n",
    "4. y: is this the latitude of the crime?\n",
    "5. bayview_binary\n",
    "6. ingleside_binary\n",
    "7. northern_binary\n",
    "8. central_binary\n",
    "9. mission_binary\n",
    "10. southern_binary\n",
    "11. tenderloin_binary\n",
    "12. park_binary\n",
    "13. richmond_binary\n",
    "14. taraval_binary\n",
    "15. HOURLYDRYBULBTEMPF\n",
    "16. HOURLYRelativeHumidity\n",
    "17. HOURLYWindSpeed\n",
    "18. HOURLYSeaLevelPressure\n",
    "19. HOURLYVISIBILITIY\n",
    "20. Daylight: = 1 if ‘DAILYSunset’ > ‘DATE’ and 0 otherwise\n",
    "\n",
    "As you can see below, the data required further cleaning and tranformation.\n",
    "\n",
    "We imputed missing values with the feature's mean value.  We then scaled features between 0 and 1.  The data was shuffled to remove any underlying pattern that may exist.\n",
    "\n",
    "Kaggle dictated that our performance metric was log loss.  This was not directly submitted by us, but computed from a submitted csv file with a matrix of the probability estimates of each class of crime for each data point.  In our work, we sought to directly optimize the log loss by hyperparameter tuning, calibrating, and applying meta-estimation to our models.  This meant that we would not be submitting our probability estimates each time we attempted to improve the performance of a model.  This posed operational difficulty though, as the log loss function in sklearn.metrics requires that the set of correct labels for the data must exactly match the set of labels as generated by the max values within the predicted probabilities.\n",
    "\n",
    "Two of the crimes in our data set were extremely rare: trespassing on an industrial property (TREA) and possessing obscene material (PORNOGRAPHY/OBSC) at 4 and 8 in approximately 1 million crimes, respectively.  At such rare rates, those crimes were not showing up in our data when randomly suhhfling and then subsetting into necessary train, development, calibration, and test subsets. This caused errors in generating log loss\n",
    "Therefore, we decided to sacrifice our performance on these rare 12 out of 1 million data points to be able to more quickly determine our performance metric.\n",
    "\n",
    "To ensure that all the data subsets contained all of the remaining crimes as labels (all 37 of them), the data load sometimes required repeated iterations in order to secure a crime set of 37 across the board.  This was due to the inability to set a seed when using the permutation method in numpy.  The data subsets were sized such that it would not require more than a few attempts to get all 37 crime labels into each subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are local file dependencies here.  For viewing comfort, we will suppress the code in order to not generate error messages.  The code that follows was written by us to incorporate the weather data features into the original data from Kaggle, and to load and then subset the data into train, development, calibrate, and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 37 37 37\n"
     ]
    }
   ],
   "source": [
    "#data_path = \"/Users/Bryan/Desktop/UC_Berkeley_MIDS_files/Courses/W207_Intro_To_Machine_Learning/Final_Project/x_data_3.csv\"\n",
    "#df = pd.read_csv(data_path, header=0)\n",
    "#x_data = df.drop('category', 1)\n",
    "#y = df.category.as_matrix()\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "#x_complete = x_data.fillna(x_data.mean())\n",
    "#X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "#X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist.  Must re-run random seed step each time:\n",
    "#np.random.seed(0)\n",
    "#shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "#X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Due to difficulties with log loss and set(y_pred) needing to match set(labels), we will remove the extremely rare\n",
    "# crimes from the data for quality issues.\n",
    "#X_minus_trea = X[np.where(y != 'TREA')]\n",
    "#y_minus_trea = y[np.where(y != 'TREA')]\n",
    "#X_final = X_minus_trea[np.where(y_minus_trea != 'PORNOGRAPHY/OBSCENE MAT')]\n",
    "#y_final = y_minus_trea[np.where(y_minus_trea != 'PORNOGRAPHY/OBSCENE MAT')]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "#test_data, test_labels = X_final[800000:], y_final[800000:]\n",
    "#dev_data, dev_labels = X_final[700000:800000], y_final[700000:800000]\n",
    "#train_data, train_labels = X_final[100000:700000], y_final[100000:700000]\n",
    "#calibrate_data, calibrate_labels = X_final[:100000], y_final[:100000]\n",
    "\n",
    "# Create mini versions of the above sets\n",
    "#mini_train_data, mini_train_labels = X_final[:20000], y_final[:20000]\n",
    "#mini_calibrate_data, mini_calibrate_labels = X_final[19000:28000], y_final[19000:28000]\n",
    "#mini_dev_data, mini_dev_labels = X_final[49000:60000], y_final[49000:60000]\n",
    "\n",
    "# Create list of the crime type labels.  This will act as the \"labels\" parameter for the log loss functions that follow\n",
    "#crime_labels = list(set(y_final))\n",
    "#crime_labels_mini_train = list(set(mini_train_labels))\n",
    "#crime_labels_mini_dev = list(set(mini_dev_labels))\n",
    "#crime_labels_mini_calibrate = list(set(mini_calibrate_labels))\n",
    "#print(len(crime_labels), len(crime_labels_mini_train), len(crime_labels_mini_dev),len(crime_labels_mini_calibrate))\n",
    "\n",
    "#print(len(train_data),len(train_labels))\n",
    "#print(len(dev_data),len(dev_labels))\n",
    "#print(len(mini_train_data),len(mini_train_labels))\n",
    "#print(len(mini_dev_data),len(mini_dev_labels))\n",
    "#print(len(test_data),len(test_labels))\n",
    "#print(len(mini_calibrate_data),len(mini_calibrate_labels))\n",
    "#print(len(calibrate_data),len(calibrate_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis Of The Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yFrame = pd.DataFrame(y, columns=['category'])\n",
    "yCounts = yFrame['category'].value_counts()\n",
    "\n",
    "f = plt.figure(figsize=(15,8))\n",
    "yCounts.plot(kind='bar')\n",
    "plt.title('Distribution of Classes in the Training Data')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate table showing the fraction of the total variance explained by the first k components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=20)\n",
    "pca1.fit(train_data)\n",
    "explainedVariances = pca1.explained_variance_ratio_\n",
    "\n",
    "totalExplained = []\n",
    "for index in range(len(explainedVariances)):\n",
    "    totalExplained.append(sum(explainedVariances[:index+1]))\n",
    "\n",
    "pd.DataFrame(totalExplained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the fraction of the total variance explained by the first k components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(np.linspace(1,20,20),totalExplained,\".\")\n",
    "plt.title(\"Fraction of Total Variance Explained by First k Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Fraction of Total Variance Explained\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Output for Kaggle\n",
    "\n",
    "Kaggle required a very specific format for submitting our results.  Submissions are evaluated using the multi-class logarithmic loss. Each incident must be labeled with one true class. For each incident, one must submit a set of predicted probabilities (one for every class).  A CSV file with the incident id, all candidate class names, and a probability for each class is required for the final submission document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Kaggle submission format requires listing the ID of each example.\n",
    "# This is to remember the order of the IDs after shuffling\n",
    "#allIDs = np.array(list(df.axes[0]))\n",
    "#allIDs = allIDs[shuffle]\n",
    "\n",
    "#testIDs = allIDs[800000:]\n",
    "#devIDs = allIDs[700000:800000]\n",
    "#trainIDs = allIDs[:700000]\n",
    "\n",
    "# Extract the column names for the required submission format\n",
    "#sampleSubmission_path = \"./data/sampleSubmission.csv\"\n",
    "#sampleDF = pd.read_csv(sampleSubmission_path)\n",
    "#allColumns = list(sampleDF.columns)\n",
    "#featureColumns = allColumns[1:]\n",
    "\n",
    "# Extracting the test data for a baseline submission\n",
    "#real_test_path = \"./data/test_transformed.csv\"\n",
    "#testDF = pd.read_csv(real_test_path, header=0)\n",
    "#real_test_data = testDF\n",
    "\n",
    "#test_complete = real_test_data.fillna(real_test_data.mean())\n",
    "#Test_raw = test_complete.as_matrix()\n",
    "\n",
    "#TestData = MinMaxScaler().fit_transform(Test_raw)\n",
    "\n",
    "# Here we remember the ID of each test data point, in case we ever decide to shuffle the test data for some reason\n",
    "#testIDs = list(testDF.axes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Baseline Prediction Probabilities from MNB classifier and store in a .csv file\n",
    "\n",
    "This step was completed as a test-run to ensure that everything up to this point was functioning properly and that we could generate a proper submission CSV file. We also provided an example of the model accuacy being generated, although this was not our formal metric for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a baseline MNB classifier and make it return prediction probabilities for the actual test data\n",
    "#def MNB():\n",
    "#    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "#    mnb.fit(train_data, train_labels)\n",
    "#    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "#    return mnb.predict_proba(dev_data)\n",
    "#MNB()\n",
    "\n",
    "#baselinePredictionProbabilities = MNB()\n",
    "\n",
    "# Place the resulting prediction probabilities in a .csv file in the required format\n",
    "# First, turn the prediction probabilties into a data frame\n",
    "#resultDF = pd.DataFrame(baselinePredictionProbabilities,columns=featureColumns)\n",
    "# Add the IDs as a final column\n",
    "#resultDF.loc[:,'Id'] = pd.Series(testIDs,index=resultDF.index)\n",
    "# Make the 'Id' column the first column\n",
    "#colnames = resultDF.columns.tolist()\n",
    "#colnames = colnames[-1:] + colnames[:-1]\n",
    "#resultDF = resultDF[colnames]\n",
    "# Output to a .csv file\n",
    "# resultDF.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: the code above will shuffle data differently every time it's run, so model accuracies will vary accordingly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We later wrote a python script to automatically generate a Kaggle-formatted CSV document for our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Aug 19 19:49:47 2017\n",
    "@author: kalvi\n",
    "\"\"\"\n",
    "\n",
    "#required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_kaggle_format(sample_submission_path, test_transformed_path, prediction_probabilities):\n",
    "    \"\"\"this function requires:\n",
    "        sample_submission_path=(filepath for 'sampleSubmission.csv')\n",
    "        test_transformed_path=(filepath for 'test_transformed.csv')\n",
    "        prediction_probabilities=(output from clf.predict_proba(test_data))\"\"\"\n",
    "    \n",
    "    #this is for extracting the column names for the required submission format\n",
    "    sampleDF = pd.read_csv(sample_submission_path)\n",
    "    allColumns = list(sampleDF.columns)\n",
    "    featureColumns = allColumns[1:]\n",
    "    \n",
    "    #this is for extracting the test data IDs for our baseline submission\n",
    "    testDF = pd.read_csv(test_transformed_path, header=0)\n",
    "    testIDs = list(testDF.axes[0])\n",
    "    \n",
    "    #first we turn the prediction probabilties into a data frame\n",
    "    resultDF = pd.DataFrame(prediction_probabilities,columns=featureColumns)\n",
    "    \n",
    "    #this adds the IDs as a final column\n",
    "    resultDF.loc[:,'Id'] = pd.Series(testIDs,index=resultDF.index)\n",
    "    \n",
    "    #the next few lines make the 'Id' column the first column\n",
    "    colnames = resultDF.columns.tolist()\n",
    "    colnames = colnames[-1:] + colnames[:-1]\n",
    "    resultDF = resultDF[colnames]\n",
    "    \n",
    "    #output to .csv file\n",
    "    resultDF.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.016  0.985  0.826  0.667  0.055  0.002  0.     0.     0.     1.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.514  0.405  0.375  0.661  1.\n",
      "   0.985  0.985  0.   ]]\n",
      "['LARCENY/THEFT']\n"
     ]
    }
   ],
   "source": [
    "## Data sub-setting quality check-point\n",
    "print(train_data[:1])\n",
    "print(train_labels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB accuracy on dev data: 0.22347\n"
     ]
    }
   ],
   "source": [
    "# Modeling quality check-point with MNB--fast model\n",
    "\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "    \n",
    "MNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Performance Criteria\n",
    "\n",
    "As determined by the Kaggle submission guidelines, the performance criteria metric for the San Francisco Crime Classification competition is Multi-class Logarithmic Loss (also known as cross-entropy).  There are various other performance metrics that are appropriate for different domains: accuracy, F-score, Lift, ROC Area, average precision, precision/recall break-even point, and squared error.\n",
    "\n",
    "- Multi-class Log Loss\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- F-score\n",
    "\n",
    "- Lift\n",
    "\n",
    "- ROC Area\n",
    "\n",
    "- Average precision\n",
    "\n",
    "- Precision/Recall break-even point\n",
    "\n",
    "- Squared-error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prototyping With Default Hyperparameters\n",
    "\n",
    "We started our classifier engineering process by looking at the performance of various classifiers with default parameter settings in predicting labels on the mini_dev_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') Multi-class Log Loss: 21.0240643644 \n",
      "\n",
      "\n",
      "BernoulliNB(alpha=1, binarize=0.5, class_prior=None, fit_prior=True) Multi-class Log Loss: 2.6947927812 \n",
      "\n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) Multi-class Log Loss: 2.60974496429 \n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) Multi-class Log Loss: 2.59547592791 \n",
      "\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) Multi-class Log Loss: 2.60265495281 \n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False) Multi-class Log Loss: 15.5020995603 \n",
      "\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best') Multi-class Log Loss: 29.8634820265 \n",
      "\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) Multi-class Log Loss: 2.62373605675 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_prototype(train_data, train_labels, eval_data, eval_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(train_data, train_labels)\n",
    "    bnb = BernoulliNB(alpha=1, binarize = 0.5).fit(train_data, train_labels)\n",
    "    mnb = MultinomialNB().fit(train_data, train_labels)\n",
    "    log_reg = LogisticRegression().fit(train_data, train_labels)\n",
    "    neural_net = MLPClassifier().fit(train_data, train_labels)\n",
    "    random_forest = RandomForestClassifier().fit(train_data, train_labels)\n",
    "    decision_tree = DecisionTreeClassifier().fit(train_data, train_labels)\n",
    "    support_vm_step_one = svm.SVC(probability = True)\n",
    "    support_vm = support_vm_step_one.fit(train_data, train_labels)\n",
    "    \n",
    "    models = [knn, bnb, mnb, log_reg, neural_net, random_forest, decision_tree, support_vm]\n",
    "    for model in models:\n",
    "        eval_prediction_probabilities = model.predict_proba(eval_data)\n",
    "        eval_predictions = model.predict(eval_data)\n",
    "        print(model, \"Multi-class Log Loss:\", log_loss(y_true = eval_labels, y_pred = eval_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "\n",
    "model_prototype(mini_train_data, mini_train_labels, mini_dev_data, mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Model Calibration To Improve Prediction For Each Classifier\n",
    "\n",
    "Here we sought to optimize the performance of our classifiers in a three-step, dynamnic engineering process. \n",
    "\n",
    "#### 1) Feature addition\n",
    "\n",
    "We previously added components from the weather data into the original SF crime data as new features.  We will not repeat work done in our initial submission, where our training dataset did not include these features.  For comparision with respoect to how the added features improved our performance with respect to log loss, please refer back to our initial submission.\n",
    "\n",
    "#### 2) Hyperparameter tuning\n",
    "\n",
    "Each classifier has hyperparameters that we can engineer to further optimize performance, as opposed to using the default parameter values as we did above in the model prototyping cell. This will be specific to each classifier as detailed below.\n",
    "\n",
    "#### 3) Model calibration\n",
    "\n",
    "We can calibrate the models via Platt Scaling or Isotonic Regression to attempt to improve their performance.\n",
    "\n",
    "- Platt Scaling: ((brief explanation of how it works))\n",
    "\n",
    "- Isotonic Regression: ((brief explanation of how it works))\n",
    "\n",
    "For each classifier, we can use CalibratedClassifierCV to perform probability calibration with isotonic regression or sigmoid (Platt Scaling).  The parameters within CalibratedClassifierCV that we can adjust are the method ('sigmoid' or 'isotonic') and cv (cross-validation generator).  As we will already be training our models before calibration, we will only use cv = 'prefit'.  Thus, in practice the cross-validation generator will not be a modifiable parameter for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Parallelizing GridSearchCV with Spark-sklearn\n",
    "\n",
    "To optimize the parameters, we used GridSearchCV -- with a slight wrinkle. Because we needed GridSearchCV to sort through an incredible number of model specifications with a very large amount of data, we decided to parallelize the process using Spark. Fortunately, there is a PyPI library for doing just that: spark-sklearn. Check out the package here.\n",
    "\n",
    "In order to run spark-sklearn, we took the following steps:\n",
    "\n",
    "- Create an AWS EC2 instance (in our case, a c3.8xlarge instance with an Ubuntu Linux operating system, with 32 vCPUs and 60GiB of memory)\n",
    "- Install: Java, Scala, Anaconda, pip, and relevant dependencies (key library: spark_sklearn)\n",
    "- Run GridSearchCV within a SparkContext\n",
    "- All of the code is the exact same as a normal GridSearchCV with scikit-learn, except for two lines:\n",
    "\n",
    "\"from spark_sklearn import GridSearchCV\"\n",
    "\n",
    "\"gs = GridSearchCV(sc, clf, param_grid)\"\n",
    "\n",
    "In other words, the grid search takes SparkContext as an extra parameter. Because of that, the process can be parallelized across multiple cores, which saves a lot of time. For more information on parallelizing GridSearchCV using Spark, see this DataBricks tutorial and this AWS EC2 PySpark tutorial. Note: we ran the PySpark code in the PySpark REPL, rather than in a script. We hit issues with dependencies using Python scripts. We appear not to be alone in this issue; other data scientists have also hit a wall using scikit-learn with Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning:\n",
    "\n",
    "For the KNN classifier, we can seek to optimize the following classifier parameters: n-neighbors, weights, and the power parameter ('p')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For KNN the best log loss with hyperparameter tuning is 2.62923629844 with k = 2001 w = uniform p = 1\n",
      "Computation time for this step is 351.40 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_ks = []\n",
    "list_for_ws = []\n",
    "list_for_ps = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def k_neighbors_tuned(k,w,p):\n",
    "    tuned_KNN = KNeighborsClassifier(n_neighbors=k, weights=w, p=p).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = tuned_KNN.predict_proba(mini_dev_data)\n",
    "    list_for_ks.append(this_k)\n",
    "    list_for_ws.append(this_w)\n",
    "    list_for_ps.append(this_p)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with KNN and k,w,p =\", k,\",\",w,\",\", p, \"is:\", working_log_loss)\n",
    "\n",
    "k_value_tuning = [i for i in range(1,5002,500)]\n",
    "weight_tuning = ['uniform', 'distance']\n",
    "power_parameter_tuning = [1,2]\n",
    "\n",
    "start = time.clock()\n",
    "for this_k in k_value_tuning:\n",
    "    for this_w in weight_tuning:\n",
    "        for this_p in power_parameter_tuning:\n",
    "            k_neighbors_tuned(this_k, this_w, this_p)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For KNN the best log loss with hyperparameter tuning is',list_for_log_loss[index_best_logloss], 'with k =', list_for_ks[index_best_logloss], 'w =', list_for_ws[index_best_logloss], 'p =', list_for_ps[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration:\n",
    "\n",
    "Here we will calibrate the KNN classifier with both Platt Scaling and with Isotonic Regression using CalibratedClassifierCV with various parameter settings.  The \"method\" parameter can be set to \"sigmoid\" or to \"isotonic\", corresponding to Platt Scaling and to Isotonic Regression respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Log Loss with KNN and k,w,p = 2 , uniform , 1 , sigmoid is: 2.70144987755\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , uniform , 1 , isotonic is: 2.70118580885\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , uniform , 2 , sigmoid is: 2.70079087512\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , uniform , 2 , isotonic is: 2.70309343586\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , distance , 1 , sigmoid is: 2.725631755\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , distance , 1 , isotonic is: 3.54686417213\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , distance , 2 , sigmoid is: 2.7248315732\n",
      "Multi-class Log Loss with KNN and k,w,p = 2 , distance , 2 , isotonic is: 3.58297553553\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , uniform , 1 , sigmoid is: 2.69314603155\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , uniform , 1 , isotonic is: 2.69304318298\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , uniform , 2 , sigmoid is: 2.68965954407\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , uniform , 2 , isotonic is: 2.69144921228\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , distance , 1 , sigmoid is: 2.72329504137\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , distance , 1 , isotonic is: 3.61148466836\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , distance , 2 , sigmoid is: 2.7190933662\n",
      "Multi-class Log Loss with KNN and k,w,p = 3 , distance , 2 , isotonic is: 3.63170844548\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , uniform , 1 , sigmoid is: 2.68775935384\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , uniform , 1 , isotonic is: 2.68847986277\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , uniform , 2 , sigmoid is: 2.68764051296\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , uniform , 2 , isotonic is: 2.68922847263\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , distance , 1 , sigmoid is: 2.71828761494\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , distance , 1 , isotonic is: 3.59984232382\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , distance , 2 , sigmoid is: 2.71789190227\n",
      "Multi-class Log Loss with KNN and k,w,p = 4 , distance , 2 , isotonic is: 3.65851135959\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , uniform , 1 , sigmoid is: 2.68412338935\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , uniform , 1 , isotonic is: 2.68153191204\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , uniform , 2 , sigmoid is: 2.68440609082\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , uniform , 2 , isotonic is: 2.68651054445\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , distance , 1 , sigmoid is: 2.71261820403\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , distance , 1 , isotonic is: 3.52999779954\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , distance , 2 , sigmoid is: 2.71291395097\n",
      "Multi-class Log Loss with KNN and k,w,p = 5 , distance , 2 , isotonic is: 3.524233494\n",
      "For KNN the best log loss with hyperparameter tuning and calibration is 2.68153191204 with k = 5 w = uniform p = 1 m = isotonic\n",
      "Computation time for this step is 231.29 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_ks = []\n",
    "list_for_ws = []\n",
    "list_for_ps = []\n",
    "list_for_ms = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def knn_calibrated(k,w,p,m):\n",
    "    tuned_KNN = KNeighborsClassifier(n_neighbors=k, weights=w, p=p).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = tuned_KNN.predict_proba(mini_dev_data)\n",
    "    ccv = CalibratedClassifierCV(tuned_KNN, method = m, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    list_for_ks.append(this_k)\n",
    "    list_for_ws.append(this_w)\n",
    "    list_for_ps.append(this_p)\n",
    "    list_for_ms.append(this_m)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    print(\"Multi-class Log Loss with KNN and k,w,p =\", k,\",\",w,\",\",p,\",\",m,\"is:\", working_log_loss)\n",
    "\n",
    "k_value_tuning = ([i for i in range(1,21,1)] + [j for j in range(25,51,5)] + [k for k in range(55,22000,1000)])\n",
    "weight_tuning = ['uniform', 'distance']\n",
    "power_parameter_tuning = [1,2]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "start = time.clock()\n",
    "for this_k in k_value_tuning:\n",
    "    for this_w in weight_tuning:\n",
    "        for this_p in power_parameter_tuning:\n",
    "            for this_m in methods:\n",
    "                knn_calibrated(this_k, this_w, this_p, this_m)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For KNN the best log loss with hyperparameter tuning and calibration is',list_for_log_loss[index_best_logloss], 'with k =', list_for_ks[index_best_logloss], 'w =', list_for_ws[index_best_logloss], 'p =', list_for_ps[index_best_logloss], 'm =', list_for_ms[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial, Bernoulli, and Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning: Bernoulli Naive Bayes\n",
    "\n",
    "For the Bernoulli Naive Bayes classifier, we seek to optimize the alpha parameter (Laplace smoothing parameter) and the binarize parameter (threshold for binarizing of the sample features).  For the binarize parameter, we will create arbitrary thresholds over which our features, which are not binary/boolean features, will be binarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For BNB the best log loss with hyperparameter tuning is 2.6247750866 with alpha = 1.2 binarization threshold = 1e-20\n",
      "Computation time for this step is 186.46 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_as = []\n",
    "list_for_bs = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def BNB_tuned(a,b):\n",
    "    bnb_tuned = BernoulliNB(alpha = a, binarize = b).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = bnb_tuned.predict_proba(mini_dev_data)\n",
    "    list_for_as.append(this_a)\n",
    "    list_for_bs.append(this_b)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with BNB and a,b =\", a,\",\",b,\"is:\", working_log_loss)\n",
    "\n",
    "alpha_tuning = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0, 1.1, 1.2, 1.4, 1.6, 1.8, 2.0, 10.0]\n",
    "binarize_thresholds_tuning = [1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999, 0.9999]\n",
    "\n",
    "start = time.clock()\n",
    "for this_a in alpha_tuning:\n",
    "    for this_b in binarize_thresholds_tuning:\n",
    "            BNB_tuned(this_a, this_b)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For BNB the best log loss with hyperparameter tuning is',list_for_log_loss[index_best_logloss], 'with alpha =', list_for_as[index_best_logloss], 'binarization threshold =', list_for_bs[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration: BernoulliNB\n",
    "\n",
    "Here we will calibrate the BNB classifier with both Platt Scaling and with Isotonic Regression using CalibratedClassifierCV with various parameter settings.  The \"method\" parameter can be set to \"sigmoid\" or to \"isotonic\", corresponding to Platt Scaling and to Isotonic Regression respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For BNB the best log loss with hyperparameter tuning and calibration is 2.61370308039 with alpha = 1.0 binarization threshold = 0.5 method =  sigmoid\n",
      "Computation time for this step is 1066.40 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_as = []\n",
    "list_for_bs = []\n",
    "list_for_ms = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def BNB_calibrated(a,b,m):\n",
    "    bnb_tuned = BernoulliNB(alpha = a, binarize = b).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = bnb_tuned.predict_proba(mini_dev_data)\n",
    "    ccv = CalibratedClassifierCV(bnb_tuned, method = m, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    list_for_as.append(this_a)\n",
    "    list_for_bs.append(this_b)\n",
    "    list_for_ms.append(this_m)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with BNB and a,b,m =\", a,\",\", b,\",\", m, \"is:\", working_log_loss)\n",
    "\n",
    "alpha_tuning = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0, 1.1, 1.2, 1.4, 1.6, 1.8, 2.0, 10.0]\n",
    "binarize_thresholds_tuning = [1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999, 0.9999]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "start = time.clock()\n",
    "for this_a in alpha_tuning:\n",
    "    for this_b in binarize_thresholds_tuning:\n",
    "            for this_m in methods:\n",
    "                BNB_calibrated(this_a, this_b, this_m)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For BNB the best log loss with hyperparameter tuning and calibration is',list_for_log_loss[index_best_logloss], 'with alpha =', list_for_as[index_best_logloss], 'binarization threshold =', list_for_bs[index_best_logloss], 'method = ', list_for_ms[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning: Multinomial Naive Bayes\n",
    "\n",
    "For the Multinomial Naive Bayes classifer, we seek to optimize the alpha parameter (Laplace smoothing parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MNB the best log loss with hyperparameter tuning is 2.60930490132 with alpha = 1.8\n",
      "Computation time for this step is 5.96 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_as = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def MNB_tuned(a):\n",
    "    mnb_tuned = MultinomialNB(alpha = a).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities =mnb_tuned.predict_proba(mini_dev_data)\n",
    "    list_for_as.append(this_a)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with BNB and a =\", a, \"is:\", working_log_loss)\n",
    "\n",
    "alpha_tuning = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0, 1.1, 1.2, 1.4, 1.6, 1.8, 2.0, 10.0]\n",
    "\n",
    "start = time.clock()\n",
    "for this_a in alpha_tuning:\n",
    "            MNB_tuned(this_a)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For MNB the best log loss with hyperparameter tuning is',list_for_log_loss[index_best_logloss], 'with alpha =', list_for_as[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration: MultinomialNB\n",
    "\n",
    "Here we will calibrate the MNB classifier with both Platt Scaling and with Isotonic Regression using CalibratedClassifierCV with various parameter settings.  The \"method\" parameter can be set to \"sigmoid\" or to \"isotonic\", corresponding to Platt Scaling and to Isotonic Regression respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MNB the best log loss with hyperparameter tuning and calibration is 2.6145055659 with alpha = 2.0 and method = sigmoid\n",
      "Computation time for this step is 34.13 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_as = []\n",
    "list_for_ms = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def MNB_calibrated(a,m):\n",
    "    mnb_tuned = MultinomialNB(alpha = a).fit(mini_train_data, mini_train_labels)\n",
    "    ccv = CalibratedClassifierCV(mnb_tuned, method = m, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    list_for_as.append(this_a)\n",
    "    list_for_ms.append(this_m)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with MNB and a =\", a, \"and m =\", m, \"is:\", working_log_loss)\n",
    "\n",
    "alpha_tuning = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0, 1.1, 1.2, 1.4, 1.6, 1.8, 2.0, 10.0]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "start = time.clock()\n",
    "for this_a in alpha_tuning:\n",
    "    for this_m in methods:\n",
    "        MNB_calibrated(this_a, this_m)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For MNB the best log loss with hyperparameter tuning and calibration is',list_for_log_loss[index_best_logloss], 'with alpha =', list_for_as[index_best_logloss], 'and method =', list_for_ms[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best parameters for Logistic Regression (run separate from this notebook on PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_param_grid = {'alpha': [0.2, 0.4, 0.6, 0.8]}\n",
    "MNB = GridSearchCV(MultinomialNB(), param_grid=mnb_param_grid, scoring = 'neg_log_loss')\n",
    "MNB.fit(train_data, train_labels)\n",
    "print(\"the best alpha value is:\", str(MNB.best_params_['alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_param_grid = {'alpha': [0.3, 0.35, 0.4, 0.45, 0.5]}\n",
    "MNB = GridSearchCV(MultinomialNB(), param_grid=mnb_param_grid, scoring = 'neg_log_loss')\n",
    "MNB.fit(train_data, train_labels)\n",
    "print(\"the best alpha value is:\", str(MNB.best_params_['alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_param_grid = {'alpha': [0.31, 0.33, 0.35, 0.37, 0.39]}\n",
    "MNB = GridSearchCV(MultinomialNB(), param_grid=mnb_param_grid, scoring = 'neg_log_loss')\n",
    "MNB.fit(train_data, train_labels)\n",
    "print(\"the best alpha value is:\", str(MNB.best_params_['alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the log loss from what we have tuned thus far\n",
    "MNBPredictionProbabilities = MNB.predict_proba(dev_data)\n",
    "print(\"Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = MNBPredictionProbabilities, labels = crime_labels), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_param_grid = {'alpha': [0.340, 0.345, 0.35, 0.355, 0.360]}\n",
    "MNB = GridSearchCV(MultinomialNB(), param_grid=mnb_param_grid, scoring = 'neg_log_loss')\n",
    "MNB.fit(train_data, train_labels)\n",
    "print(\"the best alpha value is:\", str(MNB.best_params_['alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the log loss from what we have tuned thus far\n",
    "MNBPredictionProbabilities = MNB.predict_proba(dev_data)\n",
    "print(\"Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = MNBPredictionProbabilities, labels = crime_labels), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning: Gaussian Naive Bayes\n",
    "\n",
    "For the Gaussian Naive Bayes classifier there are no inherent parameters within the classifier function to optimize, but we will look at our log loss before and after adding noise to the data that is hypothesized to give it a more normal (Gaussian) distribution, which is required by the GNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Log Loss with pre-tuned GNB is: 34.1076504549\n",
      "Multi-class Log Loss with tuned GNB via addition of noise to normalize the data's distribution is: 31.8040829494\n"
     ]
    }
   ],
   "source": [
    "def GNB_pre_tune():\n",
    "    gnb_pre_tuned = GaussianNB().fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities =gnb_pre_tuned.predict_proba(mini_dev_data)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    print(\"Multi-class Log Loss with pre-tuned GNB is:\", working_log_loss)\n",
    "\n",
    "GNB_pre_tune()\n",
    "    \n",
    "def GNB_post_tune():\n",
    "    # Gaussian Naive Bayes requires the data to have a relative normal distribution. Sometimes\n",
    "    # adding noise can improve performance by making the data more normal:\n",
    "    mini_train_data_noise = np.random.rand(mini_train_data.shape[0],mini_train_data.shape[1])\n",
    "    modified_mini_train_data = np.multiply(mini_train_data,mini_train_data_noise)    \n",
    "    gnb_with_noise = GaussianNB().fit(modified_mini_train_data,mini_train_labels)\n",
    "    dev_prediction_probabilities =gnb_with_noise.predict_proba(mini_dev_data)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    print(\"Multi-class Log Loss with tuned GNB via addition of noise to normalize the data's distribution is:\", working_log_loss)\n",
    "    \n",
    "GNB_post_tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration: GaussianNB\n",
    "\n",
    "Here we will calibrate the GNB classifier with both Platt Scaling and with Isotonic Regression using CalibratedClassifierCV with various parameter settings.  The \"method\" parameter can be set to \"sigmoid\" or to \"isotonic\", corresponding to Platt Scaling and to Isotonic Regression respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GNB the best log loss with tuning and calibration is 2.67904020299 with method = sigmoid\n",
      "Computation time for this step is 1.36 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_ms = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def GNB_calibrated(m):\n",
    "    # Gaussian Naive Bayes requires the data to have a relative normal distribution. Sometimes\n",
    "    # adding noise can improve performance by making the data more normal:\n",
    "    mini_train_data_noise = np.random.rand(mini_train_data.shape[0],mini_train_data.shape[1])\n",
    "    modified_mini_train_data = np.multiply(mini_train_data,mini_train_data_noise)    \n",
    "    gnb_with_noise = GaussianNB().fit(modified_mini_train_data,mini_train_labels)\n",
    "    ccv = CalibratedClassifierCV(gnb_with_noise, method = m, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    list_for_ms.append(this_m)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with tuned GNB via addition of noise to normalize the data's distribution and after calibration is:\", working_log_loss, 'with calibration method =', m)\n",
    "    \n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "start = time.clock()\n",
    "for this_m in methods:\n",
    "    GNB_calibrated(this_m)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For GNB the best log loss with tuning and calibration is',list_for_log_loss[index_best_logloss], 'with method =', list_for_ms[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "For the Logistic Regression classifier, we can seek to optimize the following classifier parameters: penalty (l1 or l2), C (inverse of regularization strength), solver ('newton-cg', 'lbfgs', 'liblinear', or 'sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cValsL1 = [7.5, 10.0, 12.5, 20.0]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL1:\n",
    "    for m in methods:\n",
    "        ccvL1 = CalibratedClassifierCV(LogisticRegression(penalty='l1', C=c, tol=tol), method=m, cv=cv)\n",
    "        ccvL1.fit(mini_train_data, mini_train_labels)\n",
    "        print(ccvL1.get_params)\n",
    "        ccvL1_prediction_probabilities = ccvL1.predict_proba(mini_dev_data)\n",
    "        ccvL1_predictions = ccvL1.predict(mini_dev_data)\n",
    "        print(\"L1 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL1_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cValsL1 = [15.0, 20.0, 25.0, 50.0]\n",
    "method = 'sigmoid'\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL1:\n",
    "    ccvL1 = CalibratedClassifierCV(LogisticRegression(penalty='l1', C=c, tol=tol), method=method, cv=cv)\n",
    "    ccvL1.fit(mini_train_data, mini_train_labels)\n",
    "    print(ccvL1.get_params)\n",
    "    ccvL1_prediction_probabilities = ccvL1.predict_proba(mini_dev_data)\n",
    "    ccvL1_predictions = ccvL1.predict(mini_dev_data)\n",
    "    print(\"L1 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL1_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best parameters for Logistic Regression (run separate from this notebook on PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#L1\n",
    "#lr_param_grid_1 = {'C': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "lr_param_grid_1 = {'C': [7.5, 10.0, 12.5, 15.0, 20.0, 30.0, 50.0, 100.0]}\n",
    "LR_l1 = GridSearchCV(LogisticRegression(penalty='l1'), param_grid=lr_param_grid_1, scoring='neg_log_loss')\n",
    "LR_l1.fit(train_data, train_labels)\n",
    "\n",
    "print('L1: best C value:', str(LR_l1.best_params_['C']))\n",
    "\n",
    "LR_l1_prediction_probabilities = LR_l1.predict_proba(dev_data)\n",
    "LR_l1_predictions = LR_l1.predict(dev_data)\n",
    "print(\"L1 Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = LR_l1_prediction_probabilities, labels = crime_labels), \"\\n\\n\")\n",
    "\n",
    "#create an LR-L1 classifier with the best params\n",
    "bestL1 = LogisticRegression(penalty='l1', C=LR_l1.best_params_['C'])\n",
    "bestL1.fit(train_data, train_labels)\n",
    "#L1weights = bestL1.coef_\n",
    "\n",
    "columns = ['hour_of_day','dayofweek',\\\n",
    "          'x','y','bayview','ingleside','northern',\\\n",
    "          'central','mission','southern','tenderloin',\\\n",
    "          'park','richmond','taraval','HOURLYDRYBULBTEMPF',\\\n",
    "          'HOURLYRelativeHumidity','HOURLYWindSpeed',\\\n",
    "          'HOURLYSeaLevelPressure','HOURLYVISIBILITY',\\\n",
    "          'Daylight']\n",
    "\n",
    "allCoefsL1 = pd.DataFrame(index=columns)\n",
    "for a in range(len(bestL1.coef_)):\n",
    "    allCoefsL1[crime_labels[a]] = bestL1.coef_[a]\n",
    "\n",
    "allCoefsL1\n",
    "\n",
    "f = plt.figure(figsize=(15,8))\n",
    "allCoefsL1.plot(kind='bar', figsize=(15,8))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0,0.5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#L2\n",
    "lr_param_grid_2 = {'C': [0.0001, 0.01, 1.0, 10.0, 50.0, 100.0, 150.0, 250.0, 500.0], \\\n",
    "                 'solver':['liblinear','newton-cg','lbfgs', 'sag']}\n",
    "LR_l2 = GridSearchCV(LogisticRegression(penalty='l2'), param_grid=lr_param_grid_2, scoring='neg_log_loss')\n",
    "LR_l2.fit(train_data, train_labels)\n",
    "\n",
    "print('L2: best C value:', str(LR_l2.best_params_['C']))\n",
    "print('L2: best solver:', str(LR_l2.best_params_['solver']))\n",
    "\n",
    "LR_l2_prediction_probabilities = LR_l2.predict_proba(dev_data)\n",
    "LR_l2_predictions = LR_l2.predict(dev_data)\n",
    "print(\"L2 Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = LR_l2_prediction_probabilities, labels = crime_labels), \"\\n\\n\")\n",
    "\n",
    "#create an LR-L2 classifier with the best params\n",
    "bestL2 = LogisticRegression(penalty='l2', solver=LR_l2.best_params_['solver'], C=LR_l2.best_params_['C'])\n",
    "bestL2.fit(train_data, train_labels)\n",
    "#L2weights = bestL2.coef_\n",
    "\n",
    "columns = ['hour_of_day','dayofweek',\\\n",
    "          'x','y','bayview','ingleside','northern',\\\n",
    "          'central','mission','southern','tenderloin',\\\n",
    "          'park','richmond','taraval','HOURLYDRYBULBTEMPF',\\\n",
    "          'HOURLYRelativeHumidity','HOURLYWindSpeed',\\\n",
    "          'HOURLYSeaLevelPressure','HOURLYVISIBILITY',\\\n",
    "          'Daylight']\n",
    "\n",
    "allCoefsL2 = pd.DataFrame(index=columns)\n",
    "for a in range(len(bestL2.coef_)):\n",
    "    allCoefsL2[crime_labels[a]] = bestL2.coef_[a]\n",
    "\n",
    "allCoefsL2\n",
    "\n",
    "f = plt.figure(figsize=(15,8))\n",
    "allCoefsL2.plot(kind='bar', figsize=(15,8))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "\n",
    "For the Decision Tree classifier, we can seek to optimize the following classifier parameters: \n",
    "\n",
    "- criterion: The function to measure the quality of a split; can be either Gini impurity \"gini\" or information gain \"entropy\"\n",
    "- splitter: The strategy used to choose the split at each node; can be either \"best\" to choose the best split or \"random\" to choose the best random split\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node\n",
    "- max_depth: The maximum depth of trees. If default \"None\" then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "- class_weight: The weights associated with classes; can be \"None\" giving all classes weight of one, or can be \"balanced\", which uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "- max_features: The number of features to consider when looking for the best split; can be \"int\", \"float\" (percent), \"auto\", \"sqrt\", or \"None\"\n",
    "\n",
    "Other adjustable parameters include:\n",
    "- min_samples_split: The minimum number of samples required to split an internal node; can be an integer or a float (percentage and ceil as the minimum number of samples for each node)\n",
    "- min_weight_fraction_leaf: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node; default = 0\n",
    "- max_leaf_nodes: Grosw a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If \"None\" then unlimited number of leaf nodes is used.\n",
    "- min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to the min_impurity_decrease value. Default is zero. \n",
    "\n",
    "Setting min_samples_leaf to approximately 1% of the data points can stop the tree from inappropriately classifying outliers, which can help to improve accuracy (unsure if significantly improves MCLL) []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DT the best log loss with hyperparameter tuning is 2.62645819033 with criterion = entropy splitter = best max_depth = 15 min_samples_leaf = 1201 class_weight = None max_features = 9\n",
      "Computation time for this step is 1424.48 seconds\n"
     ]
    }
   ],
   "source": [
    "list_for_cs = []\n",
    "list_for_ss = []\n",
    "list_for_mds = []\n",
    "list_for_mss = []\n",
    "list_for_cws = []\n",
    "list_for_fs = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def DT_tuned(c,s,md,ms,cw,f):\n",
    "    tuned_DT = DecisionTreeClassifier(criterion=c, splitter=s, max_depth=md, min_samples_leaf=ms, max_features=f, class_weight=cw).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = tuned_DT.predict_proba(mini_dev_data)\n",
    "    list_for_cs.append(this_c)\n",
    "    list_for_ss.append(this_s)\n",
    "    list_for_mds.append(this_md)\n",
    "    list_for_mss.append(this_ms)\n",
    "    list_for_cws.append(this_cw)\n",
    "    list_for_fs.append(this_f)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = dev_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with DT and c,s,md,ms,cw,f =\", c,\",\",s,\",\", md,\",\",ms,\",\",cw,\",\",f,\"is:\", working_log_loss)\n",
    "\n",
    "criterion_tuning = ['gini', 'entropy']\n",
    "splitter_tuning = ['best', 'random']\n",
    "max_depth_tuning = ([None,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "min_samples_leaf_tuning = [x + 1 for x in [i for i in range(0,int(0.091*len(mini_train_data)),100)]]\n",
    "class_weight_tuning = [None, 'balanced']\n",
    "max_features_tuning = ['auto', 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "start = time.clock()\n",
    "for this_c in criterion_tuning:\n",
    "    for this_s in splitter_tuning:\n",
    "        for this_md in max_depth_tuning:\n",
    "            for this_ms in min_samples_leaf_tuning:\n",
    "                for this_cw in class_weight_tuning:\n",
    "                    for this_f in max_features_tuning:\n",
    "                        DT_tuned(this_c, this_s, this_md, this_ms, this_cw, this_f)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For DT the best log loss with hyperparameter tuning is',list_for_log_loss[index_best_logloss], 'with criterion =', list_for_cs[index_best_logloss], 'splitter =', list_for_ss[index_best_logloss], 'max_depth =', list_for_mds[index_best_logloss], 'min_samples_leaf =', list_for_mss[index_best_logloss], 'class_weight =', list_for_cws[index_best_logloss], 'max_features =', list_for_fs[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , auto , sigmoid is: 2.70888798421\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , auto , isotonic is: 2.85635450179\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 2 , sigmoid is: 2.70872615427\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 2 , isotonic is: 2.80355451969\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 3 , sigmoid is: 2.69815374851\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 3 , isotonic is: 2.82892176447\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 4 , sigmoid is: 2.70032530894\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 4 , isotonic is: 2.79782811709\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 5 , sigmoid is: 2.70315008561\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 5 , isotonic is: 2.8022793479\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 6 , sigmoid is: 2.69781719577\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 6 , isotonic is: 2.77490607908\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 7 , sigmoid is: 2.69993921872\n",
      "Multi-class Log Loss with DT and c,s,md,ms,cw,f = gini , best , None , 1 , None , 7 , isotonic is: 2.76253067697\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-95506a412269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mthis_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_features_tuning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mthis_cm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                             \u001b[0mDT_calibrated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_cw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mindex_best_logloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_for_log_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-95506a412269>\u001b[0m in \u001b[0;36mDT_calibrated\u001b[0;34m(c, s, md, ms, cw, f, cm)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtuned_DT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mccv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuned_DT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'prefit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mccv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_calibrate_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_calibrate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mccv_prediction_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mccv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_dev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlist_for_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mcalibrated_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mcalibrated_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrated_classifiers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibrated_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 raise ValueError('method should be \"sigmoid\" or '\n\u001b[1;32m    342\u001b[0m                                  '\"isotonic\". Got %s.' % self.method)\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mcalibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibrator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sigmoid_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36m_sigmoid_calibration\u001b[0;34m(df, y, sample_weight)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mAB0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprior1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mAB_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAB0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mAB_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAB_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m    857\u001b[0m             'return_all': retall}\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bryan/anaconda/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         Hk = numpy.dot(A1, numpy.dot(Hk, A2)) + (rhok * sk[:, numpy.newaxis] *\n\u001b[0;32m--> 976\u001b[0;31m                                                  sk[numpy.newaxis, :])\n\u001b[0m\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[0mfval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_for_cs = []\n",
    "list_for_ss = []\n",
    "list_for_mds = []\n",
    "list_for_mss = []\n",
    "list_for_cws = []\n",
    "list_for_fs = []\n",
    "list_for_cms = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def DT_calibrated(c,s,md,ms,cw,f,cm):\n",
    "    tuned_DT = DecisionTreeClassifier(criterion=c, splitter=s, max_depth=md, min_samples_leaf=ms, max_features=f, class_weight=cw).fit(mini_train_data, mini_train_labels)\n",
    "    ccv = CalibratedClassifierCV(tuned_DT, method = cm, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    list_for_cs.append(this_c)\n",
    "    list_for_ss.append(this_s)\n",
    "    list_for_mds.append(this_md)\n",
    "    list_for_mss.append(this_ms)\n",
    "    list_for_cws.append(this_cw)\n",
    "    list_for_fs.append(this_f)\n",
    "    list_for_cms.append(this_cm)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    print(\"Multi-class Log Loss with DT and c,s,md,ms,cw,f =\", c,\",\",s,\",\", md,\",\",ms,\",\",cw,\",\",f,\",\",cm,\"is:\", working_log_loss)\n",
    "\n",
    "criterion_tuning = ['gini', 'entropy']\n",
    "splitter_tuning = ['best', 'random']\n",
    "max_depth_tuning = ([None,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "min_samples_leaf_tuning = [x + 1 for x in [i for i in range(0,int(0.091*len(mini_train_data)),100)]]\n",
    "class_weight_tuning = [None, 'balanced']\n",
    "max_features_tuning = ['auto', 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "start = time.clock()\n",
    "for this_c in criterion_tuning:\n",
    "    for this_s in splitter_tuning:\n",
    "        for this_md in max_depth_tuning:\n",
    "            for this_ms in min_samples_leaf_tuning:\n",
    "                for this_cw in class_weight_tuning:\n",
    "                    for this_f in max_features_tuning:\n",
    "                        for this_cm in methods:\n",
    "                            DT_calibrated(this_c, this_s, this_md, this_ms, this_cw, this_f, this_cm)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For DT the best log loss with hyperparameter tuning and calibration is',list_for_log_loss[index_best_logloss], 'with criterion =', list_for_cs[index_best_logloss], 'splitter =', list_for_ss[index_best_logloss], 'max_depth =', list_for_mds[index_best_logloss], 'min_samples_leaf =', list_for_mss[index_best_logloss], 'class_weight =', list_for_cws[index_best_logloss], 'max_features =', list_for_fs[index_best_logloss], 'and calibration method =', list_for_cms[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "For the SVM classifier, we can seek to optimize the following classifier parameters: C (penalty parameter C of the error term), kernel ('linear', 'poly', 'rbf', sigmoid', or 'precomputed')\n",
    "\n",
    "See source [2] for parameter optimization in SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class_labels = list(set(train_labels))\n",
    "\n",
    "def enumerateY(data):\n",
    "    enumerated_data = np.zeros(data.size)\n",
    "    for j in range(0,data.size):\n",
    "        feature = data[j]\n",
    "        i = class_labels.index(feature)\n",
    "        enumerated_data[j]+= i\n",
    "    return (np.array(enumerated_data))\n",
    "\n",
    "\n",
    "train_labels_enum = enumerateY(mini_train_labels)\n",
    "dev_labels_enum = enumerateY(mini_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal parameters\n",
    "\n",
    "parameters = {'C': (0.001, 0.01, 0.1, 0.5, 1, 5, 10, 25, 100), \n",
    "             'decision_function_shape': ('ovo', 'ovr'),\n",
    "             'kernel': ('linear', 'sigmoid', 'rbf', 'poly')}\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(tol = 0.01, probability = True), parameters, scoring = \"log_loss\")\n",
    "clf.fit(mini_train_data, mini_train_labels).predict_proba(mini_dev_data)\n",
    "print(\"optimal parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most optimal parameters returned score of 2.62651014795\n",
    "clf_svc = svm.SVC(kernel='rbf', C=100, decision_function_shape='ovr', probability = True).fit(mini_train_data, train_labels_enum)\n",
    "predicted = clf_svc.fit(mini_train_data, train_labels_enum).predict_proba(mini_dev_data)\n",
    "\n",
    "\n",
    "print(log_loss(y_true = dev_labels_enum, y_pred = predicted, labels = dev_labels_enum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "The benefit of Neural Nets is that it can learn a non-linear function for classification. Relative to that of logistic regression, you have multiple \"hidden\" layers in between the input and output layers. \n",
    "\n",
    "The disadvantages are however that 1) you could have more than one local minimum due to a convex loss function which means depending on where the weights initialize you could end up with very different results and 2) the number of hyperparameters to tune is high -- requires lots of computing power.\n",
    "\n",
    "MLP trains using backpropgation - it trains using gradient descent and for classification, it minimizes the Cross-Entropy loss function, giving a vector of probability estimates.\n",
    "\n",
    "For the Neural Networks MLP classifier, the following classifier parameters are subject to optimization: 1) hidden_layer_sizes - which includes number of hidden layers as well as number of hidden nodes; 2) activation function - 'identity', 'logistic', 'tanh', 'relu'; 3) alpha - L2 regularization term to avoid overfitting; 4) learning_rate - 'constant', 'invscaling','adaptive'; 5) solver - 'lbfgs','sgd', adam' and 6) batch size. \n",
    "\n",
    "Given the limitations to compute power, we took a targeted approach to training our MLP model. We ran gridsearchCV several times over subsets of parameters which is obviously not ideal given the number of parameters. We also attempted to test the potential impact of scikit's neural network classifier which also can incorporate drop out methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One of the iterations of gridSearchCV we ran\n",
    "\n",
    "import itertools\n",
    "hidden_layers = [2, 3, 4]\n",
    "for i in hidden_layers:\n",
    "    hidden_layer_sizes = [x for x in itertools.product((4, 8, 12, 16, 20),repeat=i)]  \n",
    "\n",
    "parameters = {'activation' : ('logistic', 'tanh', 'relu'), \n",
    "              'batch_size': (50, 100, 200), \n",
    "              'alpha': (0.001, 0.01, 0.1, 0.25), \n",
    "             'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(tol = 0.01), parameters, scoring = \"log_loss\")\n",
    "clf.fit(mini_train_data, mini_train_labels).predict_proba(mini_dev_data)\n",
    "print(\"optimal parameters: \",clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our best parameter return\n",
    "clf = MLPClassifier(tol=0.01, activation = 'tanh', hidden_layer_sizes = (20,), batch_size = 10, alpha = 0.01).fit(mini_train_data, mini_train_labels)\n",
    "predicted = clf.predict(mini_dev_data)\n",
    "predicted_prob = clf.predict_proba(mini_dev_data)\n",
    "score = log_loss(mini_dev_labels, predicted_prob)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the best performing parameters from the tuning procedures above and add dropout method to illustrate the potential impact there. Dropout method would not have materially improved the score had we used it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units = 20, dropout = .25),\n",
    "        Layer(\"Softmax\")], batch_size = 10, learning_rate = .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = nn.fit(mini_train_data, mini_train_labels)\n",
    "predicted = clf.predict(mini_dev_data)\n",
    "predicted_prob = clf.predict_proba(mini_dev_data)\n",
    "score = log_loss(mini_dev_labels, predicted_prob)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##We attempted to run a more comprehensive hyperparameter tuning procedure including number of iterations and ranges for dropout method. It was too computationally intensive. Even on a remote AWS instance on pyspark it kept stalling out. \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(nn, param_grid={\n",
    "    'learning_rate': [0.05, 0.01, 0.005, 0.001],\n",
    "    'n_iter': [25, 50, 100, 200],\n",
    "    'hidden0__units': [4, 8, 12, 16, 20],\n",
    "    'hidden0__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"],\n",
    "    'hidden0__dropout':[0.2, 0.3, 0.4],\n",
    "    'hidden1__units': [4, 8, 12, 16, 20],\n",
    "    'hidden1__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"],\n",
    "    'hidden1__dropout':[0.2, 0.3, 0.4],\n",
    "    'hidden2__units': [4, 8, 12, 16, 20],\n",
    "    'hidden2__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"],\n",
    "    'hidden2__dropout':[0.2, 0.3, 0.4]})\n",
    "gs.fit(mini_train_data, mini_train_labels)\n",
    "predicted = gs.predict(mini_dev_data)\n",
    "predicted_prob = gs.predict_proba(mini_dev_data)\n",
    "score = log_loss(mini_dev_labels, predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Further calibration using CalibratedClassifierCV\n",
    "list_for_log_loss = []\n",
    "\n",
    "def NN_calibrated():\n",
    "    tuned_NN = clf = MLPClassifier(tol=0.01, activation = 'tanh', hidden_layer_sizes = (20,), batch_size = 10, alpha = 0.001).fit(mini_train_data, mini_train_labels)\n",
    "    dev_prediction_probabilities = tuned_NN.predict_proba(mini_dev_data)\n",
    "    ccv = CalibratedClassifierCV(tuned_NN, method = m, cv = 'prefit')\n",
    "    ccv.fit(mini_calibrate_data, mini_calibrate_labels)\n",
    "    ccv_prediction_probabilities = ccv.predict_proba(mini_dev_data)\n",
    "    working_log_loss = log_loss(y_true = mini_dev_labels, y_pred = ccv_prediction_probabilities, labels = crime_labels_mini_dev)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    print(\"Multi-class Log Loss with NN is:\", working_log_loss)\n",
    "\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "\n",
    "for m in methods:\n",
    "    NN_calibrated()\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For NN the best log loss with hyperparameter tuning and calibration is',list_for_log_loss[index_best_logloss])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "For the Random Forest classifier, we can seek to optimize the following classifier parameters: n_estimators (the number of trees in the forsest), max_features, max_depth, min_samples_leaf, bootstrap (whether or not bootstrap samples are used when building trees), oob_score (whether or not out-of-bag samples are used to estimate the generalization accuracy)\n",
    "\n",
    "This information is only included in our Final Notebook.  Please refer to it.\n",
    "\n",
    "#### Model calibration:\n",
    "\n",
    "See Final Notebook please"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "For the Gradient Boosting classifier, we can seek to optimize the following classifier parameters: n_estimators (the number of trees in the forsest), max_depth, min_samples_leaf, and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning_rate : float, optional (default=0.1)\n",
    "#n_estimators : int (default=100)\n",
    "#max_depth : integer, optional (default=3)\n",
    "#criterion : string, optional (default=”friedman_mse”)\n",
    "#min_samples_split : int, float, optional (default=2)\n",
    "#min_samples_leaf : int, float, optional (default=1)\n",
    "#min_weight_fraction_leaf : float, optional (default=0.)\n",
    "#subsample : float, optional (default=1.0)\n",
    "#max_features : int, float, string or None, optional (default=None)\n",
    "#max_leaf_nodes : int or None, optional (default=None)\n",
    "\n",
    "nList = [75, 125]\n",
    "depthList = [1, 5]\n",
    "leafList = [2, 7]\n",
    "featuresList = [8, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gb_param_grid = {'n_estimators':[25, 75, 250, 750], 'max_depth': [1, 5, 9], \\\n",
    "#                 'min_samples_leaf': [2, 7, 12], 'max_features': [3, 8, 17]}\n",
    "#GB = GridSearchCV(GradientBoostingClassifier(), param_grid=gb_param_grid, scoring='neg_log_loss')\n",
    "#GB.fit(train_data, train_labels)\n",
    "\n",
    "for n_estimators in nList:\n",
    "    for max_depth in depthList:\n",
    "        for min_samples_leaf in leafList:\n",
    "            for max_features in featuresList:\n",
    "                gbTest = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, \\\n",
    "                                                    min_samples_leaf=min_samples_leaf, max_features=max_features)\n",
    "                gbTest.fit(mini_train_data, mini_train_labels)\n",
    "                gbTestPredictionProbabilities = gbTest.predict_proba(mini_dev_data)\n",
    "                print(\"Parameters:\")\n",
    "                print(\"n_estimators:\", str(n_estimators)+\";\", \" max_depth:\", str(max_depth)+\";\", \\\n",
    "                      \" min_samples_leaf:\", str(min_samples_leaf)+\";\", \" max_features:\", str(max_features))\n",
    "                print(\"Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = gbTestPredictionProbabilities, \\\n",
    "                                                        labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best parameters for Gradient Boosting (run separate from this notebook on PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_param_grid = {'n_estimators':[25, 75, 250, 750], 'max_depth': [1, 5, 9], \\\n",
    "                 'min_samples_leaf': [2, 7, 12], 'max_features': [3, 8, 17]}\n",
    "GB = GridSearchCV(GradientBoostingClassifier(), param_grid=gb_param_grid, scoring='neg_log_loss')\n",
    "GB.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB.best_params_\n",
    "GBPredictionProbabilities = GB.predict_proba(dev_data)\n",
    "print(\"Multi-class Log Loss:\", log_loss(y_true = dev_labels, y_pred = GBPredictionProbabilities, labels = crime_labels), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "For the AdaBoostClassifier, one can seek to optimize the following meta-estimator parameters: base_estimator (the possible classifiers over which you are providing a meta-estimation with Adaptive Boosting), n_estimators (the max number of estimators at which boosting is terminated), algorithm ('SAMME' or 'SAMME.R').\n",
    "\n",
    "###### Adaboosting each classifier:\n",
    "\n",
    "We considered running the AdaBoostClassifier on each different classifier from above, using the classifier settings with optimized Multi-class Log Loss after hyperparameter tuning and calibration.  However, with further research, we discovered that Adaptive Boosting in its current state can either increase or decrease performance compared to the initial, non-boosted model.  Further detail on this research with respect to KNN follows.  As such, we decided to use the Bagging meta-estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example: Adaboosting KNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not seek to apply Adaptive Boosting (AdaBoost) to our K-nearest Neighbors classifier.  It has been shown that AdaBoost actually reduces accuracy and other performance metrics when used with nearest neighbors classifiers [4].  This is because KNN is a stable algorithm with low variance, which leads to correlated errors during each iteration of AdaBoost.  There is, however, on-going research in ways to modify the AdaBoost algorithm for KNN classifiers to increase accuracy and other performance metrics. Due to the aforementioned, we will omit Adaptive Boosting of our hyperparameter tuned and calibrated KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "For the Bagging meta classifier, we can seek to optimize the following classifier parameters: n_estimators (the number of trees in the forsest), max_samples, max_features, bootstrap (whether or not bootstrap samples are used when building trees), bootstrap_features (whether features are drawn with replacement), and oob_score (whether or not out-of-bag samples are used to estimate the generalization accuracy)\n",
    "\n",
    "###### Bagging each classifier:\n",
    "\n",
    "We attempted to run the BaggingClassifier on out best model after performing the previous steps, which was Random FOrest hyperparameter-tuned and calibrated.  However, we were not able to find a way to run this in a distributed fashion, and after > 18 hours of runtime the attempt was stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_tuned = RandomForestClassifier(min_impurity_split=1, n_estimators=100, bootstrap= True, max_features=0.75, criterion='entropy', min_samples_leaf=10, max_depth=None).fit(train_data, train_labels)\n",
    "#RF_calibrated_and_tuned_pre_fit = CalibratedClassifierCV(RF_tuned, method = 'isotonic', cv = 'prefit')\n",
    "#RF_calibrated_and_tuned_fitted = RF_calibrated_and_tuned_pre_fit.fit(mini_calibrate_data,mini_calibrate_labels)\n",
    "\n",
    "list_for_ns = []\n",
    "list_for_mss = []\n",
    "list_for_mfs = []\n",
    "list_for_bs = []\n",
    "list_for_bfs = []\n",
    "list_for_os = []\n",
    "list_for_log_loss = []\n",
    "\n",
    "def Bagging_RF(n,ms,mf,b,bf,o):\n",
    "    bagging_clf = BaggingClassifier(base_estimator = RF_tuned, n_estimators = n, max_samples = ms, max_features = mf, bootstrap = b, bootstrap_features = bf, oob_score = o)\n",
    "    bagging_clf_fitted = bagging_clf.fit(train_data,train_labels)\n",
    "    bagging_prediction_probabilities = bagging_clf_fitted.predict_proba(dev_data)\n",
    "    list_for_ns.append(this_ns)\n",
    "    list_for_mss.append(this_mss)\n",
    "    list_for_mfs.append(this_mfs)\n",
    "    list_for_bs.append(this_bs)\n",
    "    list_for_bfs.append(this_bfs)\n",
    "    list_for_os.append(this_os)\n",
    "    working_log_loss = log_loss(y_true = dev_labels, y_pred = bagging_prediction_probabilities, labels = crime_labels)\n",
    "    list_for_log_loss.append(working_log_loss)\n",
    "    #print(\"Multi-class Log Loss with RF tuned/calibrated/bagged and n,ms,mf,b,bf,o =\", n,\",\",ms,\",\", mf,\",\",b,\",\",bf,\",\",o, \"is:\", working_log_loss)\n",
    "\n",
    "n_estimators_list = [i for i in range(1,1002,100)]\n",
    "max_samples_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "max_features_list = [0.1, 0.2, 0.4, 0.5, 0.75, 1.0]\n",
    "bootstrap_list =[True]\n",
    "bootstrap_features_list = [True, False]\n",
    "oob_score_list = [False]\n",
    "\n",
    "start = time.clock()\n",
    "for this_ns in n_estimators_list:\n",
    "    for this_mss in max_samples_list:\n",
    "        for this_mfs in max_features_list:\n",
    "            for this_bs in bootstrap_list:\n",
    "                for this_bfs in bootstrap_features_list:\n",
    "                    for this_os in oob_score_list:\n",
    "                        Bagging_RF(this_ns, this_mss, this_mfs, this_bs, this_bfs, this_os)\n",
    "            \n",
    "index_best_logloss = np.argmin(list_for_log_loss)\n",
    "print('For RF the best log loss with hyperparameter tuning, calibration, and bagging is',list_for_log_loss[index_best_logloss], 'with n_estimators =', list_for_ns[index_best_logloss], 'max_samples =', list_for_mss[index_best_logloss], 'max_features =', list_for_mfs[index_best_logloss], 'bootstrap =', list_for_bs[index_best_logloss], 'bootstrap_features =', list_for_bfs[index_best_logloss], 'oob_score =', list_for_os[index_best_logloss])\n",
    "end = time.clock()\n",
    "print(\"Computation time for this step is %.2f\" % (end-start), 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis On Our Best Classifier: Randon Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tuned_DT_calibrate_isotonic = RandomForestClassifier(min_impurity_split=1, \n",
    "                                       n_estimators=100, \n",
    "                                       bootstrap= True,\n",
    "                                       max_features=15,\n",
    "                                       criterion='entropy',\n",
    "                                       min_samples_leaf=10,\n",
    "                                       max_depth=None\n",
    "                                      ).fit(train_data, train_labels)\n",
    "ccv_isotonic = CalibratedClassifierCV(tuned_DT_calibrate_isotonic, method = 'isotonic', cv = 'prefit')\n",
    "ccv_isotonic.fit(calibrate_data, calibrate_labels)\n",
    "ccv_predictions = ccv_isotonic.predict(dev_data)\n",
    "ccv_prediction_probabilities_isotonic = ccv_isotonic.predict_proba(dev_data)\n",
    "working_log_loss_isotonic = log_loss(y_true = dev_labels, y_pred = ccv_prediction_probabilities_isotonic, labels = crime_labels)\n",
    "print(\"Multi-class Log Loss with RF and calibration with isotonic is:\", working_log_loss_isotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.amax(ccv_prediction_probabilities_isotonic, axis=1)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf_probabilities, clf_predictions, labels\n",
    "def error_analysis_calibration(buckets, clf_probabilities, clf_predictions, labels):\n",
    "    \"\"\"inputs:\n",
    "    clf_probabilities = clf.predict_proba(dev_data)\n",
    "    clf_predictions = clf.predict(dev_data)\n",
    "    labels = dev_labels\"\"\"\n",
    "    \n",
    "    #buckets = [0.05, 0.15, 0.3, 0.5, 0.8]\n",
    "    #buckets = [0.15, 0.25, 0.3, 1.0]\n",
    "    correct = [0 for i in buckets]\n",
    "    total = [0 for i in buckets]\n",
    "\n",
    "    lLimit = 0\n",
    "    uLimit = 0\n",
    "    for i in range(len(buckets)):\n",
    "        uLimit = buckets[i]\n",
    "        for j in range(clf_probabilities.shape[0]):\n",
    "            if (np.amax(clf_probabilities[j]) > lLimit) and (np.amax(clf_probabilities[j]) <= uLimit):\n",
    "                if clf_predictions[j] == labels[j]:\n",
    "                    correct[i] += 1\n",
    "                total[i] += 1\n",
    "        lLimit = uLimit\n",
    "        \n",
    "    print(sum(correct))\n",
    "    print(sum(total))\n",
    "    print(correct)\n",
    "    print(total)\n",
    "\n",
    "    #here we report the classifier accuracy for each posterior probability bucket\n",
    "    accuracies = []\n",
    "    for k in range(len(buckets)):\n",
    "        print(1.0*correct[k]/total[k])\n",
    "        accuracies.append(1.0*correct[k]/total[k])\n",
    "        print('p(pred) <= %.13f    total = %3d    correct = %3d    accuracy = %.3f' \\\n",
    "              %(buckets[k], total[k], correct[k], 1.0*correct[k]/total[k]))\n",
    "    plt.plot(buckets,accuracies)\n",
    "    plt.title(\"Calibration Analysis\")\n",
    "    plt.xlabel(\"Posterior Probability\")\n",
    "    plt.ylabel(\"Classifier Accuracy\")\n",
    "    \n",
    "    return buckets, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at how the posteriors are distributed in order to set the best bins in 'buckets'\n",
    "pd.DataFrame(np.amax(bestLRPredictionProbabilities, axis=1)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buckets = [0.15, 0.25, 0.3, 1.0]\n",
    "calibration_buckets, calibration_accuracies = error_analysis_calibration(buckets, clf_probabilities=bestLRPredictionProbabilities, \\\n",
    "                                                                         clf_predictions=bestLRPredictions, \\\n",
    "                                                                         labels=mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_analysis_classification_report(clf_predictions, labels):\n",
    "    \"\"\"inputs:\n",
    "    clf_predictions = clf.predict(dev_data)\n",
    "    labels = dev_labels\"\"\"\n",
    "    print('Classification Report:')\n",
    "    report = classification_report(labels, clf_predictions)\n",
    "    print(report)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_report = error_analysis_classification_report(clf_predictions=bestLRPredictions, \\\n",
    "                                                            labels=mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_analysis_confusion_matrix(label_names, clf_predictions, labels):\n",
    "    \"\"\"inputs:\n",
    "    clf_predictions = clf.predict(dev_data)\n",
    "    labels = dev_labels\"\"\"\n",
    "    cm = pd.DataFrame(confusion_matrix(labels, clf_predictions, labels=label_names))\n",
    "    cm.columns=label_names\n",
    "    cm.index=label_names\n",
    "    cm.to_csv(path_or_buf=\"./confusion_matrix.csv\")\n",
    "    #print(cm)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_analysis_confusion_matrix(label_names=crime_labels_mini_dev, clf_predictions=bestLRPredictions, \\\n",
    "                                                            labels=mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1) Hsiang, Solomon M. and Burke, Marshall and Miguel, Edward. \"Quantifying the Influence of Climate on Human Conflict\". Science, Vol 341, Issue 6151, 2013   \n",
    "\n",
    "2) Huang, Cheng-Lung. Wang, Chieh-Jen. \"A GA-based feature selection and parameters optimization for support vector machines\". Expert Systems with Applications, Vol 31, 2006, p 231-240\n",
    "\n",
    "3) https://gallery.cortanaintelligence.com/Experiment/Evaluating-and-Parameter-Tuning-a-Decision-Tree-Model-1\n",
    "\n",
    "4) Neo, Toh Koon Charlie and Ventura, Dan.  \"A directd boosting algorithm for the k-nearest neighbor classifier via local wraping of the distance metric\". Pattern Regognition Letters, Vol 33, 2012 p 92-102\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
