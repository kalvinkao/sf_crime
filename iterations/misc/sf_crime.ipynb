{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF Crime\n",
    "## W207 Final Project\n",
    "### Basic Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahcha/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sarahcha/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries:\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set random seed and format print output:\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DDL to construct table for SQL transformations:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE kaggle_sf_crime (\n",
    "dates TIMESTAMP,                                \n",
    "category VARCHAR,\n",
    "descript VARCHAR,\n",
    "dayofweek VARCHAR,\n",
    "pd_district VARCHAR,\n",
    "resolution VARCHAR,\n",
    "addr VARCHAR,\n",
    "X FLOAT,\n",
    "Y FLOAT);\n",
    "```\n",
    "#### Getting training data into a locally hosted PostgreSQL database:\n",
    "```sql\n",
    "\\copy kaggle_sf_crime FROM '/Users/Goodgame/Desktop/MIDS/207/final/sf_crime_train.csv' DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "#### SQL Query used for transformations:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  category,\n",
    "  date_part('hour', dates) AS hour_of_day,\n",
    "  CASE\n",
    "    WHEN dayofweek = 'Monday' then 1\n",
    "    WHEN dayofweek = 'Tuesday' THEN 2\n",
    "    WHEN dayofweek = 'Wednesday' THEN 3\n",
    "    WHEN dayofweek = 'Thursday' THEN 4\n",
    "    WHEN dayofweek = 'Friday' THEN 5\n",
    "    WHEN dayofweek = 'Saturday' THEN 6\n",
    "    WHEN dayofweek = 'Sunday' THEN 7\n",
    "  END AS dayofweek_numeric,\n",
    "  X,\n",
    "  Y,\n",
    "  CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'INGLESIDE' THEN 1\n",
    "    ELSE 0\n",
    "  END AS ingleside_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'NORTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS northern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'CENTRAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS central_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'BAYVIEW' THEN 1\n",
    "    ELSE 0\n",
    "  END AS pd_bayview_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'MISSION' THEN 1\n",
    "    ELSE 0\n",
    "  END AS mission_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'SOUTHERN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS southern_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TENDERLOIN' THEN 1\n",
    "    ELSE 0\n",
    "  END AS tenderloin_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'PARK' THEN 1\n",
    "    ELSE 0\n",
    "  END AS park_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'RICHMOND' THEN 1\n",
    "    ELSE 0\n",
    "  END AS richmond_binary,\n",
    "    CASE\n",
    "    WHEN pd_district = 'TARAVAL' THEN 1\n",
    "    ELSE 0\n",
    "  END AS taraval_binary\n",
    "FROM kaggle_sf_crime;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into training, development, and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/train_transformed.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "x_data = df.drop('category', 1)\n",
    "y = df.category.as_matrix()\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "x_complete = x_data.fillna(x_data.mean())\n",
    "X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist:\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "test_data, test_labels = X[800000:], y[800000:]\n",
    "dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "mini_train_data, mini_train_labels = X[:75000], y[:75000]\n",
    "mini_dev_data, mini_dev_labels = X[75000:100000], y[75000:100000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the data, version 2 with some weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/train_transformed.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "x_data = df.drop('category', 1)\n",
    "y = df.category.as_matrix()\n",
    "\n",
    "########## adding the date back in\n",
    "import csv\n",
    "import time\n",
    "import calendar\n",
    "data_path = \"./data/train.csv\"\n",
    "dataCSV = open(data_path, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allData = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "df2 = pd.DataFrame(allData)\n",
    "df2.columns = csvFields\n",
    "dates = df2['Dates']\n",
    "dates = dates.apply(time.strptime, args=(\"%Y-%m-%d %H:%M:%S\",))\n",
    "dates = dates.apply(calendar.timegm)\n",
    "print(dates.head())\n",
    "#dates = pd.to_datetime(dates)\n",
    "\n",
    "x_data['secondsFromEpoch'] = dates\n",
    "colnames = x_data.columns.tolist()\n",
    "colnames = colnames[-1:] + colnames[:-1]\n",
    "x_data = x_data[colnames]\n",
    "##########\n",
    "\n",
    "########## adding in weather data\n",
    "weatherData1 = \"./data/1027175.csv\"\n",
    "weatherData2 = \"./data/1027176.csv\"\n",
    "dataCSV = open(weatherData1, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allWeatherData1 = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "dataCSV = open(weatherData2, 'rt')\n",
    "csvData = list(csv.reader(dataCSV))\n",
    "csvFields = csvData[0] #['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "allWeatherData2 = csvData[1:]\n",
    "dataCSV.close()\n",
    "\n",
    "weatherDF1 = pd.DataFrame(allWeatherData1)\n",
    "weatherDF1.columns = csvFields\n",
    "dates1 = weatherDF1['DATE']\n",
    "\n",
    "weatherDF2 = pd.DataFrame(allWeatherData2)\n",
    "weatherDF2.columns = csvFields\n",
    "dates2 = weatherDF2['DATE']\n",
    "\n",
    "dates1 = dates1.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "dates1 = dates1.apply(calendar.timegm)\n",
    "dates2 = dates2.apply(time.strptime, args=(\"%Y-%m-%d %H:%M\",))\n",
    "dates2 = dates2.apply(calendar.timegm)\n",
    "weatherDF1['DATE'] = dates1\n",
    "weatherDF2['DATE'] = dates2\n",
    "weatherDF = pd.concat([weatherDF1,weatherDF2[32:]],ignore_index=True)\n",
    "\n",
    "#starting off with some of the easier features to work with-- more to come\n",
    "weatherMetrics = weatherDF[['DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYDewPointTempF', 'HOURLYWindSpeed', 'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY']]\n",
    "weatherMetrics = weatherMetrics.convert_objects(convert_numeric=True)\n",
    "weatherDates = weatherMetrics['DATE']\n",
    "#'DATE','HOURLYDRYBULBTEMPF','HOURLYRelativeHumidity', 'HOURLYDewPointTempF', 'HOURLYWindSpeed',\n",
    "#'HOURLYSeaLevelPressure', 'HOURLYVISIBILITY'\n",
    "timeWindow = 10800 #3 hours\n",
    "hourlyDryBulbTemp = []\n",
    "hourlyRelativeHumidity = []\n",
    "hourlyDewPointTemp = []\n",
    "hourlyWindSpeed = []\n",
    "hourlySeaLevelPressure = []\n",
    "hourlyVisibility = []\n",
    "test = 0\n",
    "for timePoint in dates:#dates is the epoch time from the kaggle data\n",
    "    relevantWeather = weatherMetrics[(weatherDates <= timePoint) & (weatherDates > timePoint - timeWindow)]\n",
    "    hourlyDryBulbTemp.append(relevantWeather['HOURLYDRYBULBTEMPF'].mean())\n",
    "    hourlyRelativeHumidity.append(relevantWeather['HOURLYRelativeHumidity'].mean())\n",
    "    hourlyDewPointTemp.append(relevantWeather['HOURLYDewPointTempF'].mean())\n",
    "    hourlyWindSpeed.append(relevantWeather['HOURLYWindSpeed'].mean())\n",
    "    hourlySeaLevelPressure.append(relevantWeather['HOURLYSeaLevelPressure'].mean())\n",
    "    hourlyVisibility.append(relevantWeather['HOURLYVISIBILITY'].mean())\n",
    "    if test%100000 == 0:\n",
    "        print(relevantWeather)\n",
    "    test += 1\n",
    "\n",
    "hourlyDryBulbTemp = pd.Series.from_array(np.array(hourlyDryBulbTemp))\n",
    "hourlyRelativeHumidity = pd.Series.from_array(np.array(hourlyRelativeHumidity))\n",
    "hourlyDewPointTemp = pd.Series.from_array(np.array(hourlyDewPointTemp))\n",
    "hourlyWindSpeed = pd.Series.from_array(np.array(hourlyWindSpeed))\n",
    "hourlySeaLevelPressure = pd.Series.from_array(np.array(hourlySeaLevelPressure))\n",
    "hourlyVisibility = pd.Series.from_array(np.array(hourlyVisibility))\n",
    "\n",
    "x_data['HOURLYDRYBULBTEMPF'] = hourlyDryBulbTemp\n",
    "x_data['HOURLYRelativeHumidity'] = hourlyRelativeHumidity\n",
    "x_data['HOURLYDewPointTempF'] = hourlyDewPointTemp\n",
    "x_data['HOURLYWindSpeed'] = hourlyWindSpeed\n",
    "x_data['HOURLYSeaLevelPressure'] = hourlySeaLevelPressure\n",
    "x_data['HOURLYVISIBILITY'] = hourlyVisibility\n",
    "\n",
    "#x_data.to_csv(path_or_buf=\"C:/MIDS/W207 final project/x_data.csv\")\n",
    "##########\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "x_complete = x_data.fillna(x_data.mean())\n",
    "X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist:\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "#X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Separate training, dev, and test data:\n",
    "test_data, test_labels = X[800000:], y[800000:]\n",
    "dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "mini_train_data, mini_train_labels = X[:75000], y[:75000]\n",
    "mini_dev_data, mini_dev_labels = X[75000:100000], y[75000:100000]\n",
    "\n",
    "#print(train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the submission format requires that we list the ID of each example?\n",
    "#this is to remember the order of the IDs after shuffling\n",
    "#(not used for anything right now)\n",
    "allIDs = np.array(list(df.axes[0]))\n",
    "allIDs = allIDs[shuffle]\n",
    "\n",
    "testIDs = allIDs[800000:]\n",
    "devIDs = allIDs[700000:800000]\n",
    "trainIDs = allIDs[:700000]\n",
    "\n",
    "#this is for extracting the column names for the required submission format\n",
    "sampleSubmission_path = \"./data/sampleSubmission.csv\"\n",
    "sampleDF = pd.read_csv(sampleSubmission_path)\n",
    "allColumns = list(sampleDF.columns)\n",
    "featureColumns = allColumns[1:]\n",
    "\n",
    "#this is for extracting the test data for our baseline submission\n",
    "real_test_path = \"./data/test_transformed.csv\"\n",
    "testDF = pd.read_csv(real_test_path, header=0)\n",
    "real_test_data = testDF\n",
    "\n",
    "test_complete = real_test_data.fillna(real_test_data.mean())\n",
    "Test_raw = test_complete.as_matrix()\n",
    "\n",
    "TestData = MinMaxScaler().fit_transform(Test_raw)\n",
    "\n",
    "#here we remember the ID of each test data point\n",
    "#(in case we ever decide to shuffle the test data for some reason)\n",
    "testIDs = list(testDF.axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.391e-01,   6.667e-01,   6.117e-02,   9.047e-04,   1.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   1.000e+00,   0.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00],\n",
       "       [  7.826e-01,   3.333e-01,   4.374e-02,   1.024e-03,   0.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   1.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00],\n",
       "       [  6.957e-01,   1.667e-01,   4.907e-02,   7.547e-04,   0.000e+00,\n",
       "          1.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00],\n",
       "       [  7.826e-01,   6.667e-01,   3.905e-02,   1.014e-03,   0.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   1.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00],\n",
       "       [  7.826e-01,   0.000e+00,   4.667e-02,   1.093e-03,   0.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   1.000e+00,\n",
       "          0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   0.000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copied the baseline classifier from below,\n",
    "#but made it return prediction probabilities for the actual test data\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    #print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "    return mnb.predict_proba(real_test_data)\n",
    "MNB()\n",
    "\n",
    "baselinePredictionProbabilities = MNB()\n",
    "\n",
    "#here is my rough attempt at putting the results (prediction probabilities)\n",
    "#in a .csv in the required format\n",
    "#first we turn the prediction probabilties into a data frame\n",
    "resultDF = pd.DataFrame(baselinePredictionProbabilities,columns=featureColumns)\n",
    "#this adds the IDs as a final column\n",
    "resultDF.loc[:,'Id'] = pd.Series(testIDs,index=resultDF.index)\n",
    "#the next few lines make the 'Id' column the first column\n",
    "colnames = resultDF.columns.tolist()\n",
    "colnames = colnames[-1:] + colnames[:-1]\n",
    "resultDF = resultDF[colnames]\n",
    "#output to .csv file\n",
    "resultDF.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: the code above will shuffle data differently every time it's run, so model accuracies will vary accordingly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.391e-01   6.667e-01   6.117e-02   9.047e-04   1.000e+00   0.000e+00\n",
      "    0.000e+00   0.000e+00   1.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "    0.000e+00   0.000e+00   0.000e+00]]\n",
      "['WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "## Data sanity checks\n",
    "print(train_data[:1])\n",
    "print(train_labels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB accuracy on dev data: 0.22314\n"
     ]
    }
   ],
   "source": [
    "# Modeling sanity check with MNB--fast model\n",
    "\n",
    "\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "    \n",
    "MNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prototyping\n",
    "Rapidly assessing the viability of different model forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_prototype(train_data, train_labels, eval_data, eval_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(train_data, train_labels)\n",
    "    bnb = BernoulliNB(alpha=1, binarize = 0.5).fit(train_data, train_labels)\n",
    "    mnb = MultinomialNB().fit(train_data, train_labels)\n",
    "    log_reg = LogisticRegression().fit(train_data, train_labels)\n",
    "    support_vm = svm.SVC().fit(train_data, train_labels)\n",
    "    neural_net = MLPClassifier().fit(train_data, train_labels)\n",
    "    random_forest = RandomForestClassifier().fit(train_data, train_labels)\n",
    "    \n",
    "    models = [knn, bnb, mnb, log_reg, support_vm, neural_net, random_forest]\n",
    "    for model in models:\n",
    "        eval_preds = model.predict(eval_data)\n",
    "        print(model, \"Accuracy:\", np.mean(eval_preds==eval_labels), \"\\n\\n\")\n",
    "\n",
    "model_prototype(mini_train_data, mini_train_labels, mini_dev_data, mini_dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def k_neighbors(k_values):\n",
    "    \n",
    "#     accuracies = []\n",
    "#     for k in k_values:\n",
    "#         clfk = KNeighborsClassifier(n_neighbors=k).fit(train_data, train_labels)\n",
    "#         dev_preds = clfk.predict(dev_data)\n",
    "#         accuracies.append(np.mean(dev_preds == dev_labels))\n",
    "#         print(\"k=\",k, \"accuracy:\", np.mean(dev_preds == dev_labels))\n",
    "#         if k == 7: \n",
    "#             print(\"\\n\\n Classification report for k = 7\", \":\\n\", \n",
    "#                   classification_report(dev_labels, dev_preds),)\n",
    "            \n",
    "# k_values = [i for i in range(7,9)]\n",
    "\n",
    "# k_neighbors(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial, Bernoulli, and Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB accuracy on dev data: 0.22314\n",
      "GaussianNB accuracy on dev data: 0.0062\n",
      "GaussianNB accuracy with added noise: 0.06857\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes accuracy when alpha = 1 (the default value): 0.22189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB accuracy when alpha = 0: 0.00155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for BNB on the dev data: {'alpha': 1e-23}\n",
      "Accuracy using the tuned Laplace smoothing parameter: 0.22189 \n",
      "\n",
      "\n",
      "p(pred) <= 0.5000000000000    total = 100000    accuracy = 0.222\n",
      "p(pred) <= 0.9000000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9900000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9990000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999900000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 1.0000000000000    total =   0    accuracy = 0.000\n"
     ]
    }
   ],
   "source": [
    "def GNB():\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, train_labels)\n",
    "    print(\"GaussianNB accuracy on dev data:\", \n",
    "          gnb.score(dev_data, dev_labels))\n",
    "    \n",
    "    # Gaussian Naive Bayes requires the data to have a relative normal distribution. Sometimes\n",
    "    # adding noise can improve performance by making the data more normal:\n",
    "    train_data_noise = np.random.rand(train_data.shape[0],train_data.shape[1])\n",
    "    modified_train_data = np.multiply(train_data,train_data_noise)    \n",
    "    gnb_noise = GaussianNB()\n",
    "    gnb.fit(modified_train_data, train_labels)\n",
    "    print(\"GaussianNB accuracy with added noise:\", \n",
    "          gnb.score(dev_data, dev_labels))    \n",
    "    \n",
    "# Going slightly deeper with hyperparameter tuning and model calibration:\n",
    "def BNB(alphas):\n",
    "    \n",
    "    bnb_one = BernoulliNB(binarize = 0.5)\n",
    "    bnb_one.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nBernoulli Naive Bayes accuracy when alpha = 1 (the default value):\",\n",
    "          bnb_one.score(dev_data, dev_labels))\n",
    "    \n",
    "    bnb_zero = BernoulliNB(binarize = 0.5, alpha=0)\n",
    "    bnb_zero.fit(train_data, train_labels)\n",
    "    print(\"BNB accuracy when alpha = 0:\", bnb_zero.score(dev_data, dev_labels))\n",
    "    \n",
    "    bnb = BernoulliNB(binarize=0.5)\n",
    "    clf = GridSearchCV(bnb, param_grid = alphas)\n",
    "    clf.fit(train_data, train_labels)\n",
    "    print(\"Best parameter for BNB on the dev data:\", clf.best_params_)\n",
    "    \n",
    "    clf_tuned = BernoulliNB(binarize = 0.5, alpha=0.00000000000000000000001)\n",
    "    clf_tuned.fit(train_data, train_labels)\n",
    "    print(\"Accuracy using the tuned Laplace smoothing parameter:\", \n",
    "          clf_tuned.score(dev_data, dev_labels), \"\\n\\n\")\n",
    "    \n",
    "\n",
    "def investigate_model_calibration(buckets, correct, total):\n",
    "    clf_tuned = BernoulliNB(binarize = 0.5, alpha=0.00000000000000000000001)\n",
    "    clf_tuned.fit(train_data, train_labels)\n",
    "    \n",
    "    # Establish data sets\n",
    "    pred_probs = clf_tuned.predict_proba(dev_data)\n",
    "    max_pred_probs = np.array(pred_probs.max(axis=1))\n",
    "    preds = clf_tuned.predict(dev_data)\n",
    "        \n",
    "    # For each bucket, look at the predictions that the model yields. \n",
    "    # Keep track of total & correct predictions within each bucket.\n",
    "    bucket_bottom = 0\n",
    "    bucket_top = 0\n",
    "    for bucket_index, bucket in enumerate(buckets):\n",
    "        bucket_top = bucket\n",
    "        for pred_index, pred in enumerate(preds):\n",
    "            if (max_pred_probs[pred_index] <= bucket_top) and (max_pred_probs[pred_index] > bucket_bottom):\n",
    "                total[bucket_index] += 1\n",
    "                if preds[pred_index] == dev_labels[pred_index]:\n",
    "                    correct[bucket_index] += 1\n",
    "        bucket_bottom = bucket_top\n",
    "\n",
    "def MNB():\n",
    "    mnb = MultinomialNB(alpha = 0.0000001)\n",
    "    mnb.fit(train_data, train_labels)\n",
    "    print(\"\\n\\nMultinomialNB accuracy on dev data:\", mnb.score(dev_data, dev_labels))\n",
    "\n",
    "alphas = {'alpha': [0.00000000000000000000001, 0.0000001, 0.0001, 0.001, \n",
    "                    0.01, 0.1, 0.0, 0.5, 1.0, 2.0, 10.0]}\n",
    "buckets = [0.5, 0.9, 0.99, 0.999, .9999, 0.99999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "MNB()\n",
    "GNB()\n",
    "BNB(alphas)\n",
    "investigate_model_calibration(buckets, correct, total)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "   accuracy = 0.0\n",
    "   if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "   print('p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Naive Bayes and Multinomial Naive Bayes models can predict whether a loan will be good or bad with XXX% accuracy.\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "The optimal Laplace smoothing parameter $\\alpha$ for the Bernoulli NB model:\n",
    "\n",
    "###### Model calibration:\n",
    "Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform') Accuracy: 0.9453125 \n",
      "\n",
      "\n",
      "BernoulliNB(alpha=1e-22, binarize=0.5, class_prior=None, fit_prior=True) Accuracy: 0.947265625 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def model_test(train_data, train_labels, eval_data, eval_labels):\n",
    "#     '''Similar to the initial model prototyping, but using the \n",
    "#     tuned parameters on data that none of the models have yet\n",
    "#     encountered.'''\n",
    "#     knn = KNeighborsClassifier(n_neighbors=7).fit(train_data, train_labels)\n",
    "#     bnb = BernoulliNB(alpha=0.0000000000000000000001, binarize = 0.5).fit(train_data, train_labels)\n",
    "    \n",
    "#     models = [knn, bnb]\n",
    "#     for model in models:\n",
    "#         eval_preds = model.predict(eval_data)\n",
    "#         print(model, \"Accuracy:\", np.mean(eval_preds==eval_labels), \"\\n\\n\")\n",
    "\n",
    "# model_test(train_data, train_labels, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
>>>>>>> sf_crime_sarah
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.0"
=======
   "version": "3.5.2"
>>>>>>> sf_crime_sarah
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
