{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle San Francisco Crime Classification\n",
    "## Berkeley MIDS W207 Final Project: Sam Goodgame, Sarah Cha, Kalvin Kao, Bryan Moore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Additional Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import relevant libraries:\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import Meta-estimators\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Import Calibration tools\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Set random seed and format print output:\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local, individual load of updated data set (with weather data integrated) into training, development, and test subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "700000 700000\n",
      "100000 100000\n",
      "200000 200000\n",
      "50000 50000\n",
      "78049 78049\n"
     ]
    }
   ],
   "source": [
    "# Data path to your local copy of Kalvin's \"x_data.csv\", which was produced by the negated cell above\n",
    "data_path = \"./data/x_data_3.csv\"\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "x_data = df.drop('category', 1)\n",
    "y = df.category.as_matrix()\n",
    "\n",
    "# Impute missing values with mean values:\n",
    "#x_complete = df.fillna(df.mean())\n",
    "x_complete = x_data.fillna(x_data.mean())\n",
    "X_raw = x_complete.as_matrix()\n",
    "\n",
    "# Scale the data between 0 and 1:\n",
    "X = MinMaxScaler().fit_transform(X_raw)\n",
    "\n",
    "####\n",
    "X = np.around(X, decimals=2)\n",
    "####\n",
    "\n",
    "# Shuffle data to remove any underlying pattern that may exist.  Must re-run random seed step each time:\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "test_data, test_labels = X[800000:], y[800000:]\n",
    "dev_data, dev_labels = X[700000:800000], y[700000:800000]\n",
    "train_data, train_labels = X[:700000], y[:700000]\n",
    "\n",
    "mini_train_data, mini_train_labels = X[:200000], y[:200000]\n",
    "mini_dev_data, mini_dev_labels = X[430000:480000], y[430000:480000]\n",
    "\n",
    "crime_labels = list(set(y))\n",
    "crime_labels_mini_train = list(set(mini_train_labels))\n",
    "crime_labels_mini_dev = list(set(mini_dev_labels))\n",
    "print(len(crime_labels), len(crime_labels_mini_train), len(crime_labels_mini_dev))\n",
    "\n",
    "print(len(train_data),len(train_labels))\n",
    "print(len(dev_data),len(dev_labels))\n",
    "print(len(mini_train_data),len(mini_train_labels))\n",
    "print(len(mini_dev_data),len(mini_dev_labels))\n",
    "print(len(test_data),len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "###### Hyperparameter tuning:\n",
    "\n",
    "For the Logistic Regression classifier, we can seek to optimize the following classifier parameters: penalty (l1 or l2), C (inverse of regularization strength), solver ('newton-cg', 'lbfgs', 'liblinear', or 'sag')\n",
    "\n",
    "###### Model calibration:\n",
    "\n",
    "See above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with L1-Penalty Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=7.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59363350608 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=7.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L1 Multi-class Log Loss: 2.59820996935 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59402132419 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L1 Multi-class Log Loss: 2.59946882833 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=12.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.5941487727 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=12.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L1 Multi-class Log Loss: 2.59609966677 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=20.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59328418226 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=20.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L1 Multi-class Log Loss: 2.59720190359 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cValsL1 = [7.5, 10.0, 12.5, 20.0]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL1:\n",
    "    for m in methods:\n",
    "        ccvL1 = CalibratedClassifierCV(LogisticRegression(penalty='l1', C=c, tol=tol), method=m, cv=cv)\n",
    "        ccvL1.fit(mini_train_data, mini_train_labels)\n",
    "        print(ccvL1.get_params)\n",
    "        ccvL1_prediction_probabilities = ccvL1.predict_proba(mini_dev_data)\n",
    "        ccvL1_predictions = ccvL1.predict(mini_dev_data)\n",
    "        print(\"L1 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL1_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=15.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59361567486 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=20.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59346681891 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=25.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59370161208 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=50.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L1 Multi-class Log Loss: 2.59343398529 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cValsL1 = [15.0, 20.0, 25.0, 50.0]\n",
    "method = 'sigmoid'\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL1:\n",
    "    ccvL1 = CalibratedClassifierCV(LogisticRegression(penalty='l1', C=c, tol=tol), method=method, cv=cv)\n",
    "    ccvL1.fit(mini_train_data, mini_train_labels)\n",
    "    print(ccvL1.get_params)\n",
    "    ccvL1_prediction_probabilities = ccvL1.predict_proba(mini_dev_data)\n",
    "    ccvL1_predictions = ccvL1.predict(mini_dev_data)\n",
    "    print(\"L1 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL1_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['hour_of_day','dayofweek',\\\n",
    "          'x','y','bayview','ingleside','northern',\\\n",
    "          'central','mission','southern','tenderloin',\\\n",
    "          'park','richmond','taraval','HOURLYDRYBULBTEMPF',\\\n",
    "          'HOURLYRelativeHumidity','HOURLYWindSpeed',\\\n",
    "          'HOURLYSeaLevelPressure','HOURLYVISIBILITY',\\\n",
    "          'Daylight']\n",
    "\n",
    "allCoefsL1 = pd.DataFrame(index=columns)\n",
    "for a in range(len(bestL1.coef_)):\n",
    "    allCoefsL1[crime_labels[a]] = bestL1.coef_[a]\n",
    "\n",
    "allCoefsL1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,8))\n",
    "allCoefsL1.plot(kind='bar', figsize=(15,8))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with L2-Penalty Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=75.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L2 Multi-class Log Loss: 2.59296475865 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=75.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59205373852 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L2 Multi-class Log Loss: 2.59280974183 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59179017552 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=150.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L2 Multi-class Log Loss: 2.59260678146 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=150.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59163576738 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=250.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='sigmoid')>\n",
      "L2 Multi-class Log Loss: 2.59240081814 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=250.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59117964114 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cValsL2 = [75.0, 100.0, 150.0, 250.0]\n",
    "methods = ['sigmoid', 'isotonic']\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL2:\n",
    "    for m in methods:\n",
    "        ccvL2 = CalibratedClassifierCV(LogisticRegression(penalty='l2', solver='newton-cg', C=c, tol=tol), method=m, cv=cv)\n",
    "        ccvL2.fit(mini_train_data, mini_train_labels)\n",
    "        print(ccvL2.get_params)\n",
    "        ccvL2_prediction_probabilities = ccvL2.predict_proba(mini_dev_data)\n",
    "        ccvL2_predictions = ccvL2.predict(mini_dev_data)\n",
    "        print(\"L2 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL2_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=200.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59131148618 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=200.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59131148618 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=250.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59117964114 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=250.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59117964114 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=300.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59115584585 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=300.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59115584585 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=500.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59107616746 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=500.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59107616746 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cValsL2 = [200.0, 250.0, 300.0, 500.0]\n",
    "method = 'isotonic'\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL2:\n",
    "    for m in methods:\n",
    "        ccvL2 = CalibratedClassifierCV(LogisticRegression(penalty='l2', solver='newton-cg', C=c, tol=tol), method=method, cv=cv)\n",
    "        ccvL2.fit(mini_train_data, mini_train_labels)\n",
    "        print(ccvL2.get_params)\n",
    "        ccvL2_prediction_probabilities = ccvL2.predict_proba(mini_dev_data)\n",
    "        ccvL2_predictions = ccvL2.predict(mini_dev_data)\n",
    "        print(\"L2 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL2_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=400.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.5911239027 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=400.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.5911239027 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=500.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59107616746 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=500.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59107616746 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=750.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59112328532 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=750.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.01,\n",
      "          verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59112328532 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='newton-cg', tol=0.01, verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59158821469 \n",
      "\n",
      "\n",
      "\n",
      "<bound method BaseEstimator.get_params of CalibratedClassifierCV(base_estimator=LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='newton-cg', tol=0.01, verbose=0, warm_start=False),\n",
      "            cv=2, method='isotonic')>\n",
      "L2 Multi-class Log Loss: 2.59158821469 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cValsL2 = [400.0, 500.0, 750.0, 1000.0]\n",
    "method = 'isotonic'\n",
    "cv = 2\n",
    "tol = 0.01\n",
    "for c in cValsL2:\n",
    "    for m in methods:\n",
    "        ccvL2 = CalibratedClassifierCV(LogisticRegression(penalty='l2', solver='newton-cg', C=c, tol=tol), method=method, cv=cv)\n",
    "        ccvL2.fit(mini_train_data, mini_train_labels)\n",
    "        print(ccvL2.get_params)\n",
    "        ccvL2_prediction_probabilities = ccvL2.predict_proba(mini_dev_data)\n",
    "        ccvL2_predictions = ccvL2.predict(mini_dev_data)\n",
    "        print(\"L2 Multi-class Log Loss:\", log_loss(y_true = mini_dev_labels, y_pred = ccvL2_prediction_probabilities, labels = crime_labels_mini_dev), \"\\n\\n\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['hour_of_day','dayofweek',\\\n",
    "          'x','y','bayview','ingleside','northern',\\\n",
    "          'central','mission','southern','tenderloin',\\\n",
    "          'park','richmond','taraval','HOURLYDRYBULBTEMPF',\\\n",
    "          'HOURLYRelativeHumidity','HOURLYWindSpeed',\\\n",
    "          'HOURLYSeaLevelPressure','HOURLYVISIBILITY',\\\n",
    "          'Daylight']\n",
    "\n",
    "allCoefsL2 = pd.DataFrame(index=columns)\n",
    "for a in range(len(bestL2.coef_)):\n",
    "    allCoefsL2[crime_labels[a]] = bestL2.coef_[a]\n",
    "\n",
    "allCoefsL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,8))\n",
    "allCoefsL2.plot(kind='bar', figsize=(15,8))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0,0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
